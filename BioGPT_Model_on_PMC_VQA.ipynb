{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp2EZiwmoKNF"
      },
      "source": [
        "# Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhNov3MAe_y",
        "outputId": "d6554157-d78e-4468-e286-21d76cfa9227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxbjyHcWA9xy",
        "outputId": "5672264e-e125-4077-9ef9-826311c2dbd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/sampled_images.zip\n",
            "replace /content/sampled_images/__MACOSX/._sampled_images? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/sampled_images.zip -d /content/sampled_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfDBwYEby7xR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df_new = pd.read_csv(\"/content/train_df_sampled.csv\")\n",
        "test_df = pd.read_csv(\"/content/test_df_sampled.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccAzK5ag5OBy"
      },
      "outputs": [],
      "source": [
        "train_df_new['choice'] = 'Choice ' + train_df_new['Answer']\n",
        "test_df['choice'] = 'Choice ' + test_df['Answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "z3m8jZRM5m_k",
        "outputId": "c18ba485-390b-4411-9aea-394dc2ffab10"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df_new\",\n  \"rows\": 50868,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 411444,\n        \"min\": 35,\n        \"max\": 1564845,\n        \"num_unique_values\": 50868,\n        \"samples\": [\n          837518,\n          1007013,\n          669542\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Figure_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48937,\n        \"samples\": [\n          \"PMC3062562_pone-0017879-g005_90788.jpg\",\n          \"PMC2747414_F0003_46447.jpg\",\n          \"PMC5735089_Fig4_254417.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42221,\n        \"samples\": [\n          \"Coronal CT scan showing a 2\\u2009cm homogenous inferomedial cystic mass in the right orbit.\",\n          \"Polymorphic lipid infiltration, no glycogen . Staining : periodic acid \\u2013 Schiff, hematoxylin, and orange G ; magnification \\u00d7200.\",\n          \"array of R-cells with central rhabdomeres is disrupted (B\\u2032 arrows) and there appears to be cell debris (B\\u2032 arrowhead) in these regions . Electron micrographs reveal regions where the external eye has collapsed and the facets have been obliterated (C\\u2032, D\\u2032) . A transverse section through the eyes reveals the normal length (E.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45100,\n        \"samples\": [\n          \"What radiological finding was seen on the CT chest? \",\n          \" How did the lesion appear on enhanced CT images?\",\n          \"What is being shown in the image labeled \\\"h-h\\\"? \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34266,\n        \"samples\": [\n          \" A:PH2 photographic dataset \",\n          \" A: White blood cells \",\n          \" A: Extracellular bacteria \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35195,\n        \"samples\": [\n          \" B:T2*-weighted imaging \",\n          \" B:Rectification result \",\n          \" B: Right Vocal Cord \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice C\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35929,\n        \"samples\": [\n          \" C: T1-weighted imaging \",\n          \" C:To illustrate a single vertebra inside a larger spine dataset \",\n          \" C: anterior arch \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice D\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35250,\n        \"samples\": [\n          \" D: Normal physiological uptake \",\n          \" D: Nose \",\n          \" D:It is in the kidney \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"D\",\n          \"A\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48937,\n        \"samples\": [\n          \"sampled_images/train/PMC3062562_pone-0017879-g005_90788.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"choice\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Choice D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df_new"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8b44944c-f86e-4482-a955-baa8641e3389\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Figure_path</th>\n",
              "      <th>Caption</th>\n",
              "      <th>Question</th>\n",
              "      <th>Choice A</th>\n",
              "      <th>Choice B</th>\n",
              "      <th>Choice C</th>\n",
              "      <th>Choice D</th>\n",
              "      <th>Answer</th>\n",
              "      <th>split</th>\n",
              "      <th>img_path</th>\n",
              "      <th>choice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>366653</td>\n",
              "      <td>PMC3172304_pone-0024730-g002_108440.jpg</td>\n",
              "      <td>FL-SPION-labeled macrophage migration to FUS-t...</td>\n",
              "      <td>What modality was used to obtain the images?</td>\n",
              "      <td>A: CT</td>\n",
              "      <td>B: MRI</td>\n",
              "      <td>C: PET</td>\n",
              "      <td>D: X-ray</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC3172304_pone-0024730-g...</td>\n",
              "      <td>Choice B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>689647</td>\n",
              "      <td>PMC7237059_FIG2_173889.jpg</td>\n",
              "      <td>CT scan of orbit showing the mass encasing the...</td>\n",
              "      <td>What is the imaging technique used in this ca...</td>\n",
              "      <td>A: MRI</td>\n",
              "      <td>B: CT scan</td>\n",
              "      <td>C: PET scan</td>\n",
              "      <td>D: X-ray</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC7237059_FIG2_173889.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>559748</td>\n",
              "      <td>PMC4506837_fig3_407380.jpg</td>\n",
              "      <td>the lesion with a number of hyperintense tiny ...</td>\n",
              "      <td>What is the likely diagnosis based on the ima...</td>\n",
              "      <td>A: leiomyoma</td>\n",
              "      <td>B: lipomatous tumor</td>\n",
              "      <td>C: endometrial carcinoma</td>\n",
              "      <td>D: sarcoma.</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC4506837_fig3_407380.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1104684</td>\n",
              "      <td>PMC6318116_FIG3_418363.jpg</td>\n",
              "      <td>Repeat computed tomography of chest showing ri...</td>\n",
              "      <td>What is the finding of the repeated computed ...</td>\n",
              "      <td>A:Left lung consolidation</td>\n",
              "      <td>B:Right upper lobe consolidation</td>\n",
              "      <td>C:Lower lobe consolidation</td>\n",
              "      <td>D:No consolidation found</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC6318116_FIG3_418363.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>767866</td>\n",
              "      <td>PMC7603775_Fig7_288978.jpg</td>\n",
              "      <td>round calcified lesions at the laminae of C3 a...</td>\n",
              "      <td>Where are the calcified lesions located?</td>\n",
              "      <td>A: Ventral cord</td>\n",
              "      <td>B: Laminae of C3 and C4</td>\n",
              "      <td>C: Spinal nerves</td>\n",
              "      <td>D: Cerebral cortex</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC7603775_Fig7_288978.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b44944c-f86e-4482-a955-baa8641e3389')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b44944c-f86e-4482-a955-baa8641e3389 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b44944c-f86e-4482-a955-baa8641e3389');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-73c502ff-c65f-47fd-8c15-66dfc2db4d59\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73c502ff-c65f-47fd-8c15-66dfc2db4d59')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-73c502ff-c65f-47fd-8c15-66dfc2db4d59 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     index                              Figure_path  \\\n",
              "0   366653  PMC3172304_pone-0024730-g002_108440.jpg   \n",
              "1   689647               PMC7237059_FIG2_173889.jpg   \n",
              "2   559748               PMC4506837_fig3_407380.jpg   \n",
              "3  1104684               PMC6318116_FIG3_418363.jpg   \n",
              "4   767866               PMC7603775_Fig7_288978.jpg   \n",
              "\n",
              "                                             Caption  \\\n",
              "0  FL-SPION-labeled macrophage migration to FUS-t...   \n",
              "1  CT scan of orbit showing the mass encasing the...   \n",
              "2  the lesion with a number of hyperintense tiny ...   \n",
              "3  Repeat computed tomography of chest showing ri...   \n",
              "4  round calcified lesions at the laminae of C3 a...   \n",
              "\n",
              "                                            Question  \\\n",
              "0      What modality was used to obtain the images?    \n",
              "1   What is the imaging technique used in this ca...   \n",
              "2   What is the likely diagnosis based on the ima...   \n",
              "3   What is the finding of the repeated computed ...   \n",
              "4           Where are the calcified lesions located?   \n",
              "\n",
              "                      Choice A                            Choice B  \\\n",
              "0                       A: CT                              B: MRI    \n",
              "1                      A: MRI                          B: CT scan    \n",
              "2               A: leiomyoma                 B: lipomatous tumor     \n",
              "3   A:Left lung consolidation    B:Right upper lobe consolidation    \n",
              "4             A: Ventral cord             B: Laminae of C3 and C4    \n",
              "\n",
              "                       Choice C                    Choice D Answer  split  \\\n",
              "0                       C: PET                    D: X-ray       B  train   \n",
              "1                  C: PET scan                   D: X-ray        B  train   \n",
              "2    C: endometrial carcinoma                  D: sarcoma.       B  train   \n",
              "3   C:Lower lobe consolidation    D:No consolidation found       B  train   \n",
              "4             C: Spinal nerves          D: Cerebral cortex       B  train   \n",
              "\n",
              "                                            img_path    choice  \n",
              "0  sampled_images/train/PMC3172304_pone-0024730-g...  Choice B  \n",
              "1    sampled_images/train/PMC7237059_FIG2_173889.jpg  Choice B  \n",
              "2    sampled_images/train/PMC4506837_fig3_407380.jpg  Choice B  \n",
              "3    sampled_images/train/PMC6318116_FIG3_418363.jpg  Choice B  \n",
              "4    sampled_images/train/PMC7603775_Fig7_288978.jpg  Choice B  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czm3Mt4n6_sr"
      },
      "outputs": [],
      "source": [
        "def get_answer(row):\n",
        "    return row[row[\"choice\"]][3:]\n",
        "\n",
        "train_df_new[\"Final_Answer\"] = train_df_new.apply(get_answer, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX2kzhuvGNwg"
      },
      "outputs": [],
      "source": [
        "test_df[\"Final_Answer\"] = test_df.apply(get_answer, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "Plco6dZt7LQN",
        "outputId": "aa002f27-2483-431c-8ca6-a699ef672fa9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df_new\",\n  \"rows\": 50868,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 411444,\n        \"min\": 35,\n        \"max\": 1564845,\n        \"num_unique_values\": 50868,\n        \"samples\": [\n          837518,\n          1007013,\n          669542\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Figure_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48937,\n        \"samples\": [\n          \"PMC3062562_pone-0017879-g005_90788.jpg\",\n          \"PMC2747414_F0003_46447.jpg\",\n          \"PMC5735089_Fig4_254417.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42221,\n        \"samples\": [\n          \"Coronal CT scan showing a 2\\u2009cm homogenous inferomedial cystic mass in the right orbit.\",\n          \"Polymorphic lipid infiltration, no glycogen . Staining : periodic acid \\u2013 Schiff, hematoxylin, and orange G ; magnification \\u00d7200.\",\n          \"array of R-cells with central rhabdomeres is disrupted (B\\u2032 arrows) and there appears to be cell debris (B\\u2032 arrowhead) in these regions . Electron micrographs reveal regions where the external eye has collapsed and the facets have been obliterated (C\\u2032, D\\u2032) . A transverse section through the eyes reveals the normal length (E.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45100,\n        \"samples\": [\n          \"What radiological finding was seen on the CT chest? \",\n          \" How did the lesion appear on enhanced CT images?\",\n          \"What is being shown in the image labeled \\\"h-h\\\"? \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34266,\n        \"samples\": [\n          \" A:PH2 photographic dataset \",\n          \" A: White blood cells \",\n          \" A: Extracellular bacteria \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35195,\n        \"samples\": [\n          \" B:T2*-weighted imaging \",\n          \" B:Rectification result \",\n          \" B: Right Vocal Cord \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice C\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35929,\n        \"samples\": [\n          \" C: T1-weighted imaging \",\n          \" C:To illustrate a single vertebra inside a larger spine dataset \",\n          \" C: anterior arch \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice D\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35250,\n        \"samples\": [\n          \" D: Normal physiological uptake \",\n          \" D: Nose \",\n          \" D:It is in the kidney \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"D\",\n          \"A\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48937,\n        \"samples\": [\n          \"sampled_images/train/PMC3062562_pone-0017879-g005_90788.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"choice\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Choice D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Final_Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 37365,\n        \"samples\": [\n          \" Right side of the sigmoidal sinus \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df_new"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-19f04a6e-71e5-4ede-a5a3-beca3b3a0782\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Figure_path</th>\n",
              "      <th>Caption</th>\n",
              "      <th>Question</th>\n",
              "      <th>Choice A</th>\n",
              "      <th>Choice B</th>\n",
              "      <th>Choice C</th>\n",
              "      <th>Choice D</th>\n",
              "      <th>Answer</th>\n",
              "      <th>split</th>\n",
              "      <th>img_path</th>\n",
              "      <th>choice</th>\n",
              "      <th>Final_Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>366653</td>\n",
              "      <td>PMC3172304_pone-0024730-g002_108440.jpg</td>\n",
              "      <td>FL-SPION-labeled macrophage migration to FUS-t...</td>\n",
              "      <td>What modality was used to obtain the images?</td>\n",
              "      <td>A: CT</td>\n",
              "      <td>B: MRI</td>\n",
              "      <td>C: PET</td>\n",
              "      <td>D: X-ray</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC3172304_pone-0024730-g...</td>\n",
              "      <td>Choice B</td>\n",
              "      <td>MRI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>689647</td>\n",
              "      <td>PMC7237059_FIG2_173889.jpg</td>\n",
              "      <td>CT scan of orbit showing the mass encasing the...</td>\n",
              "      <td>What is the imaging technique used in this ca...</td>\n",
              "      <td>A: MRI</td>\n",
              "      <td>B: CT scan</td>\n",
              "      <td>C: PET scan</td>\n",
              "      <td>D: X-ray</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC7237059_FIG2_173889.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "      <td>CT scan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>559748</td>\n",
              "      <td>PMC4506837_fig3_407380.jpg</td>\n",
              "      <td>the lesion with a number of hyperintense tiny ...</td>\n",
              "      <td>What is the likely diagnosis based on the ima...</td>\n",
              "      <td>A: leiomyoma</td>\n",
              "      <td>B: lipomatous tumor</td>\n",
              "      <td>C: endometrial carcinoma</td>\n",
              "      <td>D: sarcoma.</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC4506837_fig3_407380.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "      <td>lipomatous tumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1104684</td>\n",
              "      <td>PMC6318116_FIG3_418363.jpg</td>\n",
              "      <td>Repeat computed tomography of chest showing ri...</td>\n",
              "      <td>What is the finding of the repeated computed ...</td>\n",
              "      <td>A:Left lung consolidation</td>\n",
              "      <td>B:Right upper lobe consolidation</td>\n",
              "      <td>C:Lower lobe consolidation</td>\n",
              "      <td>D:No consolidation found</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC6318116_FIG3_418363.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "      <td>Right upper lobe consolidation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>767866</td>\n",
              "      <td>PMC7603775_Fig7_288978.jpg</td>\n",
              "      <td>round calcified lesions at the laminae of C3 a...</td>\n",
              "      <td>Where are the calcified lesions located?</td>\n",
              "      <td>A: Ventral cord</td>\n",
              "      <td>B: Laminae of C3 and C4</td>\n",
              "      <td>C: Spinal nerves</td>\n",
              "      <td>D: Cerebral cortex</td>\n",
              "      <td>B</td>\n",
              "      <td>train</td>\n",
              "      <td>sampled_images/train/PMC7603775_Fig7_288978.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "      <td>Laminae of C3 and C4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19f04a6e-71e5-4ede-a5a3-beca3b3a0782')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19f04a6e-71e5-4ede-a5a3-beca3b3a0782 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19f04a6e-71e5-4ede-a5a3-beca3b3a0782');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-832e1771-86b9-4d81-aca7-d6a754cca35f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-832e1771-86b9-4d81-aca7-d6a754cca35f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-832e1771-86b9-4d81-aca7-d6a754cca35f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     index                              Figure_path  \\\n",
              "0   366653  PMC3172304_pone-0024730-g002_108440.jpg   \n",
              "1   689647               PMC7237059_FIG2_173889.jpg   \n",
              "2   559748               PMC4506837_fig3_407380.jpg   \n",
              "3  1104684               PMC6318116_FIG3_418363.jpg   \n",
              "4   767866               PMC7603775_Fig7_288978.jpg   \n",
              "\n",
              "                                             Caption  \\\n",
              "0  FL-SPION-labeled macrophage migration to FUS-t...   \n",
              "1  CT scan of orbit showing the mass encasing the...   \n",
              "2  the lesion with a number of hyperintense tiny ...   \n",
              "3  Repeat computed tomography of chest showing ri...   \n",
              "4  round calcified lesions at the laminae of C3 a...   \n",
              "\n",
              "                                            Question  \\\n",
              "0      What modality was used to obtain the images?    \n",
              "1   What is the imaging technique used in this ca...   \n",
              "2   What is the likely diagnosis based on the ima...   \n",
              "3   What is the finding of the repeated computed ...   \n",
              "4           Where are the calcified lesions located?   \n",
              "\n",
              "                      Choice A                            Choice B  \\\n",
              "0                       A: CT                              B: MRI    \n",
              "1                      A: MRI                          B: CT scan    \n",
              "2               A: leiomyoma                 B: lipomatous tumor     \n",
              "3   A:Left lung consolidation    B:Right upper lobe consolidation    \n",
              "4             A: Ventral cord             B: Laminae of C3 and C4    \n",
              "\n",
              "                       Choice C                    Choice D Answer  split  \\\n",
              "0                       C: PET                    D: X-ray       B  train   \n",
              "1                  C: PET scan                   D: X-ray        B  train   \n",
              "2    C: endometrial carcinoma                  D: sarcoma.       B  train   \n",
              "3   C:Lower lobe consolidation    D:No consolidation found       B  train   \n",
              "4             C: Spinal nerves          D: Cerebral cortex       B  train   \n",
              "\n",
              "                                            img_path    choice  \\\n",
              "0  sampled_images/train/PMC3172304_pone-0024730-g...  Choice B   \n",
              "1    sampled_images/train/PMC7237059_FIG2_173889.jpg  Choice B   \n",
              "2    sampled_images/train/PMC4506837_fig3_407380.jpg  Choice B   \n",
              "3    sampled_images/train/PMC6318116_FIG3_418363.jpg  Choice B   \n",
              "4    sampled_images/train/PMC7603775_Fig7_288978.jpg  Choice B   \n",
              "\n",
              "                      Final_Answer  \n",
              "0                             MRI   \n",
              "1                         CT scan   \n",
              "2               lipomatous tumor    \n",
              "3  Right upper lobe consolidation   \n",
              "4            Laminae of C3 and C4   "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "bymSFa8VGSC3",
        "outputId": "d1d625ca-245f-46a9-95eb-d8046d6181e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 11143,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 391067,\n        \"min\": 68,\n        \"max\": 1398485,\n        \"num_unique_values\": 11143,\n        \"samples\": [\n          29867,\n          1144652,\n          1191500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Figure_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10627,\n        \"samples\": [\n          \"PMC9272224_ccr36025-fig-0001_337101.jpg\",\n          \"PMC8230009_brainsci-11-00746-f002_478054.jpg\",\n          \"PMC8684580_ccr35190-fig-0002_142196.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9054,\n        \"samples\": [\n          \"The 18F-THK5351Ventricular CSF(t) time activity curve (TAC) and the image-derived arterial blood curve, averaged over all subjects . The tracer TAC peaked approximately within 2\\u00a0min after injection . The lines marked a.\",\n          \"cells at the stage of neural rosettes   (a) Maximum intensity projections (MIP) of confocal micrographs of immunofluorescence assays for PCDH19 and \\u03b2III-tubulin showing the structure of neural rosettes derived from CTRL, PCDH19mut and mixed iPSCs . Scale bar = 20 \\u03bcm . 3D rendering shows the type of division close to the center of the rosettes.\",\n          \"axial sections of 18F-FDG-PET scan showing increased metabolic activity of right pleural nodules.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10423,\n        \"samples\": [\n          \"What does the right side of the figure illustrate? \",\n          \"Where was the plaque located?\",\n          \" At what level of the body was the image taken? \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8518,\n        \"samples\": [\n          \" A: Aspergillus \",\n          \" A: Twisted extension wires \",\n          \" A: Decreasing edema  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8706,\n        \"samples\": [\n          \" B:Lung \",\n          \" B: Musca domestica  \",\n          \" B: Caries \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice C\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8834,\n        \"samples\": [\n          \" C:CD21 \",\n          \" C: Table 3   \",\n          \" C: Subcostal view \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice D\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8713,\n        \"samples\": [\n          \" D:Anterior inferior iliac spine  \",\n          \" D: Multifocal lens\",\n          \" D: Adenoma \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"D\",\n          \"A\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10627,\n        \"samples\": [\n          \"sampled_images/test/PMC9272224_ccr36025-fig-0001_337101.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"choice\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Choice D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Final_Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9018,\n        \"samples\": [\n          \" lateral radiograph \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-11fe38ac-a2a3-400c-a986-4a207ec41ee5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Figure_path</th>\n",
              "      <th>Caption</th>\n",
              "      <th>Question</th>\n",
              "      <th>Choice A</th>\n",
              "      <th>Choice B</th>\n",
              "      <th>Choice C</th>\n",
              "      <th>Choice D</th>\n",
              "      <th>Answer</th>\n",
              "      <th>split</th>\n",
              "      <th>img_path</th>\n",
              "      <th>choice</th>\n",
              "      <th>Final_Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58420</td>\n",
              "      <td>PMC8519188_FIG5_85295.jpg</td>\n",
              "      <td>CT scan of the chest post - chemotherapy showi...</td>\n",
              "      <td>What does the image depict about the patient's...</td>\n",
              "      <td>A:The tumor has grown larger</td>\n",
              "      <td>B:The tumor has shrunk</td>\n",
              "      <td>C:The tumor has not changed</td>\n",
              "      <td>D:The image doesn't show tumor regression</td>\n",
              "      <td>B</td>\n",
              "      <td>test</td>\n",
              "      <td>sampled_images/test/PMC8519188_FIG5_85295.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "      <td>The tumor has shrunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10664</td>\n",
              "      <td>PMC8285465_Fig3_10775.jpg</td>\n",
              "      <td>Orbit magnetic resonance imaging (MRI) at the ...</td>\n",
              "      <td>What imaging technique was used to capture th...</td>\n",
              "      <td>A:CT scan</td>\n",
              "      <td>B:Electroencephalography</td>\n",
              "      <td>C:X-ray</td>\n",
              "      <td>D:Magnetic resonance imaging</td>\n",
              "      <td>D</td>\n",
              "      <td>test</td>\n",
              "      <td>sampled_images/test/PMC8285465_Fig3_10775.jpg</td>\n",
              "      <td>Choice D</td>\n",
              "      <td>Magnetic resonance imaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>173124</td>\n",
              "      <td>PMC8918112_Fig4_221411.jpg</td>\n",
              "      <td>posterior pole (Pos) is at the right in all ph...</td>\n",
              "      <td>What is located to the right in all the photog...</td>\n",
              "      <td>A:The anterior pole</td>\n",
              "      <td>B:The posterior pole</td>\n",
              "      <td>C:The vegetal pole</td>\n",
              "      <td>D:The lateral pole</td>\n",
              "      <td>B</td>\n",
              "      <td>test</td>\n",
              "      <td>sampled_images/test/PMC8918112_Fig4_221411.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "      <td>The posterior pole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>883387</td>\n",
              "      <td>PMC8225413_fig2_475661.jpg</td>\n",
              "      <td>Excisional biopsy revealing inguinal node meta...</td>\n",
              "      <td>What does the excisional biopsy reveal in this...</td>\n",
              "      <td>A:Primary tumor</td>\n",
              "      <td>B: Epidural tumor</td>\n",
              "      <td>C: Inguinal node metastasis</td>\n",
              "      <td>D: Distant metastasis to liver.</td>\n",
              "      <td>C</td>\n",
              "      <td>test</td>\n",
              "      <td>sampled_images/test/PMC8225413_fig2_475661.jpg</td>\n",
              "      <td>Choice C</td>\n",
              "      <td>Inguinal node metastasis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>186762</td>\n",
              "      <td>PMC9015882_fig2_255557.jpg</td>\n",
              "      <td>The prone position and posterolateral approach...</td>\n",
              "      <td>What approach was used for the surgery?</td>\n",
              "      <td>A:Anterior approach</td>\n",
              "      <td>B: Posterior approach</td>\n",
              "      <td>C: Medial approach</td>\n",
              "      <td>D: Lateral approach</td>\n",
              "      <td>B</td>\n",
              "      <td>test</td>\n",
              "      <td>sampled_images/test/PMC9015882_fig2_255557.jpg</td>\n",
              "      <td>Choice B</td>\n",
              "      <td>Posterior approach</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11fe38ac-a2a3-400c-a986-4a207ec41ee5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11fe38ac-a2a3-400c-a986-4a207ec41ee5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11fe38ac-a2a3-400c-a986-4a207ec41ee5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-428bab61-55b6-42bd-b857-2aa5f66c40aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-428bab61-55b6-42bd-b857-2aa5f66c40aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-428bab61-55b6-42bd-b857-2aa5f66c40aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    index                 Figure_path  \\\n",
              "0   58420   PMC8519188_FIG5_85295.jpg   \n",
              "1   10664   PMC8285465_Fig3_10775.jpg   \n",
              "2  173124  PMC8918112_Fig4_221411.jpg   \n",
              "3  883387  PMC8225413_fig2_475661.jpg   \n",
              "4  186762  PMC9015882_fig2_255557.jpg   \n",
              "\n",
              "                                             Caption  \\\n",
              "0  CT scan of the chest post - chemotherapy showi...   \n",
              "1  Orbit magnetic resonance imaging (MRI) at the ...   \n",
              "2  posterior pole (Pos) is at the right in all ph...   \n",
              "3  Excisional biopsy revealing inguinal node meta...   \n",
              "4  The prone position and posterolateral approach...   \n",
              "\n",
              "                                            Question  \\\n",
              "0  What does the image depict about the patient's...   \n",
              "1   What imaging technique was used to capture th...   \n",
              "2  What is located to the right in all the photog...   \n",
              "3  What does the excisional biopsy reveal in this...   \n",
              "4           What approach was used for the surgery?    \n",
              "\n",
              "                         Choice A                    Choice B  \\\n",
              "0   A:The tumor has grown larger      B:The tumor has shrunk    \n",
              "1                      A:CT scan    B:Electroencephalography    \n",
              "2            A:The anterior pole        B:The posterior pole    \n",
              "3                A:Primary tumor           B: Epidural tumor    \n",
              "4           A:Anterior approach        B: Posterior approach    \n",
              "\n",
              "                        Choice C                                     Choice D  \\\n",
              "0   C:The tumor has not changed    D:The image doesn't show tumor regression    \n",
              "1                       C:X-ray                 D:Magnetic resonance imaging    \n",
              "2            C:The vegetal pole                           D:The lateral pole    \n",
              "3   C: Inguinal node metastasis              D: Distant metastasis to liver.    \n",
              "4            C: Medial approach                          D: Lateral approach    \n",
              "\n",
              "  Answer split                                        img_path    choice  \\\n",
              "0      B  test   sampled_images/test/PMC8519188_FIG5_85295.jpg  Choice B   \n",
              "1      D  test   sampled_images/test/PMC8285465_Fig3_10775.jpg  Choice D   \n",
              "2      B  test  sampled_images/test/PMC8918112_Fig4_221411.jpg  Choice B   \n",
              "3      C  test  sampled_images/test/PMC8225413_fig2_475661.jpg  Choice C   \n",
              "4      B  test  sampled_images/test/PMC9015882_fig2_255557.jpg  Choice B   \n",
              "\n",
              "                  Final_Answer  \n",
              "0        The tumor has shrunk   \n",
              "1  Magnetic resonance imaging   \n",
              "2          The posterior pole   \n",
              "3    Inguinal node metastasis   \n",
              "4          Posterior approach   "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8Vd7GwloQaw"
      },
      "source": [
        "# Install and Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PnUjWtglrAvE",
        "outputId": "dc60253f-1119-40b9-afa7-7dcd7305053a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install transformers\n",
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-3B-WvA4MPH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AdamW,\n",
        "    AutoFeatureExtractor,\n",
        "    SwinModel,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryF4B39Esz35",
        "outputId": "7494b0fe-c11b-4daa-97f5-d295e67b8235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2024.11.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v36aLDuNoUf0"
      },
      "source": [
        "# Design Dataset Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJoTUO_muHBb"
      },
      "outputs": [],
      "source": [
        "class VisualQuestionDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataframe,\n",
        "        tokenizer,\n",
        "        image_feature_extractor,\n",
        "        max_length=128,\n",
        "        include_caption=False,\n",
        "        caption_column=\"Caption\",\n",
        "        subset_size=None\n",
        "    ):\n",
        "\n",
        "        if subset_size is not None:\n",
        "            if subset_size > len(dataframe):\n",
        "                raise ValueError(\"subset_size exceeds the size of the dataset.\")\n",
        "            self.dataframe = dataframe.sample(n=subset_size, random_state=42).reset_index(drop=True)\n",
        "            print(f\"Using a subset of {subset_size} samples for the dataset.\")\n",
        "        else:\n",
        "            self.dataframe = dataframe\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.image_feature_extractor = image_feature_extractor\n",
        "        self.max_length = max_length\n",
        "        self.include_caption = include_caption\n",
        "        self.caption_column = caption_column\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join('/content/sampled_images/', row[\"img_path\"])\n",
        "        if not os.path.isfile(img_path):\n",
        "            raise FileNotFoundError(f\"Image file not found: {img_path}\")\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Preprocess image\n",
        "        image_inputs = self.image_feature_extractor(images=image, return_tensors=\"pt\")\n",
        "        pixel_values = image_inputs['pixel_values'].squeeze(0)  # (3, H, W)\n",
        "\n",
        "        # Get question and answer\n",
        "        question = row[\"Question\"]\n",
        "        answer = row[\"Final_Answer\"]\n",
        "\n",
        "        # Include caption if required\n",
        "        if self.include_caption and self.caption_column in row and pd.notnull(row[self.caption_column]):\n",
        "            caption = row[self.caption_column]\n",
        "            combined_question = f\"Caption: {caption} Question: {question}\"\n",
        "        else:\n",
        "            combined_question = question\n",
        "\n",
        "        # Tokenize question\n",
        "        question_enc = self.tokenizer(\n",
        "            combined_question,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        question_input_ids = question_enc[\"input_ids\"].squeeze(0)\n",
        "        question_attention_mask = question_enc[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        # Tokenize answer\n",
        "        answer_enc = self.tokenizer(\n",
        "            answer,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        answer_input_ids = answer_enc[\"input_ids\"].squeeze(0)\n",
        "        answer_attention_mask = answer_enc[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        labels = answer_input_ids.clone()\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": pixel_values,\n",
        "            \"question_input_ids\": question_input_ids,\n",
        "            \"question_attention_mask\": question_attention_mask,\n",
        "            \"answer_input_ids\": answer_input_ids,\n",
        "            \"answer_attention_mask\": answer_attention_mask,\n",
        "            \"labels\": labels,\n",
        "            \"question\": question,\n",
        "            \"answer\": answer\n",
        "        }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3jWIdeQoYIN"
      },
      "source": [
        "# Design Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGH70Z_HcqKk"
      },
      "outputs": [],
      "source": [
        "class BioGPTWithCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        biogpt_model_path,\n",
        "        image_encoder_type=\"swin\",  # \"swin\" or \"resnet\"\n",
        "        freeze_image_encoder=False,\n",
        "        projection_size=512,\n",
        "        num_cross_attention_layers=2,\n",
        "        fusion_method=\"add\"  # \"add\" or \"concat\"\n",
        "    ):\n",
        "\n",
        "        super(BioGPTWithCrossAttention, self).__init__()\n",
        "\n",
        "        # Load BioGPT\n",
        "        self.biogpt = AutoModelForCausalLM.from_pretrained(biogpt_model_path)\n",
        "        self.embed_dim = self.biogpt.get_input_embeddings().embedding_dim\n",
        "\n",
        "        # Initialize Image Encoder\n",
        "        if image_encoder_type.lower() == \"swin\":\n",
        "            self.image_encoder = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "            in_features = self.image_encoder.config.hidden_size\n",
        "            print(\"Initialized Swin Transformer as image encoder.\")\n",
        "        elif image_encoder_type.lower() == \"resnet\":\n",
        "            self.image_encoder = models.resnet50(pretrained=True)\n",
        "            in_features = self.image_encoder.fc.in_features\n",
        "            self.image_encoder.fc = nn.Identity()  # Remove the classification layer\n",
        "            print(\"Initialized ResNet50 as image encoder.\")\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported image encoder type\")\n",
        "\n",
        "        if freeze_image_encoder:\n",
        "            for param in self.image_encoder.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(\"Image encoder parameters are frozen.\")\n",
        "        else:\n",
        "            print(\"Image encoder parameters are trainable.\")\n",
        "\n",
        "        self.image_projection = nn.Sequential(\n",
        "            nn.Linear(in_features, projection_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(projection_size, self.embed_dim)\n",
        "        )\n",
        "        print(f\"Image projection layers initialized with projection size {projection_size}.\")\n",
        "\n",
        "        # Initialize Cross-Attention Layers\n",
        "        self.num_cross_attention_layers = num_cross_attention_layers\n",
        "        self.fusion_method = fusion_method.lower()\n",
        "\n",
        "        self.cross_attention_layers = nn.ModuleList()\n",
        "        self.norm_layers = nn.ModuleList()\n",
        "\n",
        "        for _ in range(num_cross_attention_layers):\n",
        "            self.cross_attention_layers.append(\n",
        "                nn.MultiheadAttention(embed_dim=self.embed_dim, num_heads=8, batch_first=True)\n",
        "            )\n",
        "            self.norm_layers.append(\n",
        "                nn.LayerNorm(self.embed_dim)\n",
        "            )\n",
        "            print(f\"Initialized cross-attention layer {_ + 1}.\")\n",
        "\n",
        "        # Fusion method layers\n",
        "        if self.fusion_method == \"concat\":\n",
        "            self.fusion_projection = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "            print(\"Fusion method set to 'concat'. Fusion projection layer initialized.\")\n",
        "        elif self.fusion_method == \"add\":\n",
        "            print(\"Fusion method set to 'add'. No additional projection layer needed.\")\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported fusion method. Choose 'add' or 'concat'.\")\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        pixel_values,\n",
        "        question_input_ids,\n",
        "        question_attention_mask,\n",
        "        answer_input_ids,\n",
        "        answer_attention_mask,\n",
        "        labels=None\n",
        "    ):\n",
        "        batch_size = pixel_values.size(0)\n",
        "\n",
        "        if isinstance(self.image_encoder, SwinModel):\n",
        "            image_outputs = self.image_encoder(pixel_values=pixel_values)\n",
        "            visual_embeddings = image_outputs.last_hidden_state.mean(dim=1)\n",
        "        else:\n",
        "            visual_embeddings = self.image_encoder(pixel_values)\n",
        "\n",
        "        # Project image features\n",
        "        visual_embeddings = self.image_projection(visual_embeddings)\n",
        "        visual_embeddings = visual_embeddings.unsqueeze(1)\n",
        "\n",
        "        question_embeddings = self.biogpt.get_input_embeddings()(question_input_ids)\n",
        "\n",
        "        for idx in range(self.num_cross_attention_layers):\n",
        "            cross_attn = self.cross_attention_layers[idx]\n",
        "            norm = self.norm_layers[idx]\n",
        "\n",
        "\n",
        "            attn_output, _ = cross_attn(\n",
        "                query=question_embeddings,\n",
        "                key=visual_embeddings,\n",
        "                value=visual_embeddings,\n",
        "                need_weights=False\n",
        "            )\n",
        "\n",
        "            if self.fusion_method == \"concat\":\n",
        "                combined = torch.cat((question_embeddings, attn_output), dim=-1)\n",
        "                combined = self.fusion_projection(combined)\n",
        "                question_embeddings = norm(question_embeddings + combined)\n",
        "            elif self.fusion_method == \"add\":\n",
        "                question_embeddings = norm(question_embeddings + attn_output)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported fusion method.\")\n",
        "\n",
        "        answer_embeddings = self.biogpt.get_input_embeddings()(answer_input_ids)\n",
        "\n",
        "        for idx in range(self.num_cross_attention_layers):\n",
        "            cross_attn = self.cross_attention_layers[idx]\n",
        "            norm = self.norm_layers[idx]\n",
        "\n",
        "            attn_output, _ = cross_attn(\n",
        "                query=answer_embeddings,\n",
        "                key=question_embeddings,\n",
        "                value=question_embeddings,\n",
        "                need_weights=False\n",
        "            )\n",
        "\n",
        "            if self.fusion_method == \"concat\":\n",
        "                combined = torch.cat((answer_embeddings, attn_output), dim=-1)\n",
        "                combined = self.fusion_projection(combined)\n",
        "                answer_embeddings = norm(answer_embeddings + combined)\n",
        "            elif self.fusion_method == \"add\":\n",
        "                answer_embeddings = norm(answer_embeddings + attn_output)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported fusion method.\")\n",
        "\n",
        "        outputs = self.biogpt(\n",
        "            inputs_embeds=answer_embeddings,\n",
        "            attention_mask=answer_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ10k8tRobov"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9zDkmYDcvSZ"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    epochs=5,\n",
        "    log_interval=100,\n",
        "    num_freeze_epochs=2\n",
        "):\n",
        "\n",
        "    model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\")\n",
        "\n",
        "        for step, batch in progress_bar:\n",
        "            # Move data to device\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            question_input_ids = batch[\"question_input_ids\"].to(device)\n",
        "            question_attention_mask = batch[\"question_attention_mask\"].to(device)\n",
        "            answer_input_ids = batch[\"answer_input_ids\"].to(device)\n",
        "            answer_attention_mask = batch[\"answer_attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(\n",
        "                    pixel_values=pixel_values,\n",
        "                    question_input_ids=question_input_ids,\n",
        "                    question_attention_mask=question_attention_mask,\n",
        "                    answer_input_ids=answer_input_ids,\n",
        "                    answer_attention_mask=answer_attention_mask,\n",
        "                    labels=labels\n",
        "                )\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if (step + 1) % log_interval == 0:\n",
        "                avg_loss = epoch_loss / (step + 1)\n",
        "                progress_bar.set_postfix({\"Average Loss\": f\"{avg_loss:.4f}\"})\n",
        "                print(f\"Step [{step + 1}/{len(train_loader)}] - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            if epoch <= num_freeze_epochs:\n",
        "                pass\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch} completed. Average Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOLvmKtNc19l"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(\n",
        "    model,\n",
        "    test_loader,\n",
        "    tokenizer,\n",
        "    device,\n",
        "    num_examples_to_show=3\n",
        "):\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    ground_truths = []\n",
        "    questions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"Evaluating\")):\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            question_input_ids = batch[\"question_input_ids\"].to(device)\n",
        "            question_attention_mask = batch[\"question_attention_mask\"].to(device)\n",
        "            answer_input_ids = batch[\"answer_input_ids\"].to(device)\n",
        "            answer_attention_mask = batch[\"answer_attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            question_texts = batch[\"question\"]\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                pixel_values=pixel_values,\n",
        "                question_input_ids=question_input_ids,\n",
        "                question_attention_mask=question_attention_mask,\n",
        "                answer_input_ids=answer_input_ids,\n",
        "                answer_attention_mask=answer_attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Get predicted tokens\n",
        "            pred_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            # Decode predictions\n",
        "            pred_answers = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "            # Decode ground truths\n",
        "            labels_for_decoding = labels.clone()\n",
        "            labels_for_decoding[labels_for_decoding == -100] = tokenizer.pad_token_id\n",
        "            true_answers = tokenizer.batch_decode(labels_for_decoding, skip_special_tokens=True)\n",
        "\n",
        "            predictions.extend(pred_answers)\n",
        "            ground_truths.extend(true_answers)\n",
        "            questions.extend(question_texts)\n",
        "\n",
        "            if (batch_idx + 1) <= num_examples_to_show:\n",
        "                print(f\"\\nSample {batch_idx + 1}:\")\n",
        "                print(f\"Question: {question_texts[0]}\")\n",
        "                print(f\"Prediction: {pred_answers[0]}\")\n",
        "                print(f\"Ground Truth: {true_answers[0]}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "\n",
        "    return predictions, ground_truths, questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate Model Using GPT4-o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R61OSsi3fIPd"
      },
      "outputs": [],
      "source": [
        "def evaluate_with_gpt4(predictions, ground_truths, questions, num_examples_to_show=3, max_eval_samples = 100):\n",
        "    evaluations = []\n",
        "    scores = []\n",
        "    client = OpenAI(\n",
        "    api_key=\"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\"  # This is the default and can be omitted\n",
        "    )\n",
        "\n",
        "    total_samples = len(predictions)\n",
        "    sample_size = min(max_eval_samples, total_samples)\n",
        "    indices = random.sample(range(total_samples), sample_size)\n",
        "\n",
        "    sampled_predictions = [predictions[i] for i in indices]\n",
        "    sampled_ground_truths = [ground_truths[i] for i in indices]\n",
        "    sampled_questions = [questions[i] for i in indices]\n",
        "\n",
        "    for q, pred, gt in tqdm(zip(sampled_questions, sampled_predictions, sampled_ground_truths)):\n",
        "        prompt = f\"\"\"\n",
        "You are a medical expert. Evaluate the following response to a medical question:\n",
        "\n",
        "Question: {q}\n",
        "Correct Answer: {gt}\n",
        "Model's Answer: {pred}\n",
        "\n",
        "Focus on helpfulness, relevance, and clarity of the model's answer. Try to be kind with the model and set your evaluation to be not soft. If the answer includes at least one key information, you should give at least half of the score. If the result gives all important key infromation, give full score even it offers some addtional symbols or characters. You don't need the model to explain too much details to gain a high score. Give good score if the answer is close with the real answer. Give a short assessment and at the end write:\n",
        "\"Rating: X/10\" where X is an integer score between 0 and 10.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt,\n",
        "                }\n",
        "            ],\n",
        "            model=\"gpt-4o\",\n",
        "        )\n",
        "\n",
        "\n",
        "        gpt4_assessment = response.choices[0].message.content.strip()\n",
        "        evaluations.append(gpt4_assessment)\n",
        "\n",
        "        match = re.search(r\"Rating:\\s*(\\d+)/10\", gpt4_assessment)\n",
        "        if match:\n",
        "            rating = int(match.group(1))\n",
        "            score = rating / 10.0\n",
        "        else:\n",
        "            score = 0.0\n",
        "        print('--------')\n",
        "        print('Question is: ' , q)\n",
        "        print('Groud Truth is: ', gt)\n",
        "        print('Prediction is: ', pred)\n",
        "        print('GPT-4 Evaluation:\\n', gpt4_assessment)\n",
        "        print(f\"Numeric Score: {score:.2f}\")\n",
        "        scores.append(score)\n",
        "\n",
        "    # Compute average score\n",
        "    average_score = sum(scores) / len(scores)\n",
        "\n",
        "    print(f\"Average score (0-1 scale): {average_score:.4f}\")\n",
        "    return evaluations, scores, average_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Ablation Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uxbxtAWc7B9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoFeatureExtractor\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "\n",
        "def run_ablation_study(\n",
        "    train_df,\n",
        "    test_df,\n",
        "    ablation_configs,\n",
        "    tokenizer,\n",
        "    device,\n",
        "    image_feature_extractor_name=\"swin\",  # For illustration; adjust as needed\n",
        "    subset_size=None  # To use a smaller dataset if required\n",
        "):\n",
        "\n",
        "    def get_image_feature_extractor(image_encoder_type):\n",
        "        if image_encoder_type.lower() == \"swin\":\n",
        "            feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "        elif image_encoder_type.lower() == \"resnet\":\n",
        "            from torchvision import transforms\n",
        "            feature_extractor = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported image encoder type.\")\n",
        "        return feature_extractor\n",
        "\n",
        "    for idx, config in enumerate(ablation_configs, 1):\n",
        "        print(f\"\\n{'='*20} Ablation Study {idx} {'='*20}\")\n",
        "        print(f\"Configuration: {config}\")\n",
        "\n",
        "        image_encoder_type = config.get(\"image_encoder_type\", \"swin\")\n",
        "        freeze_image_encoder = config.get(\"freeze_image_encoder\", False)\n",
        "        num_cross_attention_layers = config.get(\"num_cross_attention_layers\", 2)\n",
        "        projection_size = config.get(\"projection_size\", 512)\n",
        "        include_caption = config.get(\"include_caption\", False)\n",
        "        fusion_method = config.get(\"fusion_method\", \"add\")\n",
        "        current_subset_size = config.get(\"subset_size\", subset_size)\n",
        "\n",
        "        image_feature_extractor = get_image_feature_extractor(image_encoder_type)\n",
        "\n",
        "        train_dataset = VisualQuestionDataset(\n",
        "            dataframe=train_df,\n",
        "            tokenizer=tokenizer,\n",
        "            image_feature_extractor=image_feature_extractor,\n",
        "            max_length=128,\n",
        "            include_caption=include_caption,\n",
        "            caption_column=\"Caption\",\n",
        "            subset_size=current_subset_size\n",
        "        )\n",
        "        test_dataset = VisualQuestionDataset(\n",
        "            dataframe=test_df,\n",
        "            tokenizer=tokenizer,\n",
        "            image_feature_extractor=image_feature_extractor,\n",
        "            max_length=128,\n",
        "            include_caption=include_caption,\n",
        "            caption_column=\"Caption\",\n",
        "            subset_size=current_subset_size\n",
        "        )\n",
        "\n",
        "        # Initialize DataLoaders\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=64,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            pin_memory=True\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=64,\n",
        "            shuffle=False,\n",
        "            num_workers=4,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        # Initialize Model\n",
        "        model = BioGPTWithCrossAttention(\n",
        "            biogpt_model_path=\"microsoft/biogpt\",\n",
        "            image_encoder_type=image_encoder_type,\n",
        "            freeze_image_encoder=freeze_image_encoder,\n",
        "            projection_size=projection_size,\n",
        "            num_cross_attention_layers=num_cross_attention_layers,\n",
        "            fusion_method=fusion_method\n",
        "        ).to(device)\n",
        "\n",
        "        # Initialize Optimizer and Scheduler\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
        "        total_steps = len(train_loader) * config.get(\"epochs\", 5)\n",
        "        warmup_steps = total_steps // 10\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=warmup_steps,\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        # Train the Model\n",
        "        train_model(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            optimizer=optimizer,\n",
        "            scheduler=scheduler,\n",
        "            device=device,\n",
        "            epochs=config.get(\"epochs\", 5),\n",
        "            log_interval=config.get(\"log_interval\", 100),\n",
        "            num_freeze_epochs=config.get(\"num_freeze_epochs\", 2)\n",
        "        )\n",
        "\n",
        "        # Evaluate the Model\n",
        "        predictions, ground_truths, questions = evaluate_model(\n",
        "            model=model,\n",
        "            test_loader=test_loader,\n",
        "            tokenizer=tokenizer,\n",
        "            device=device,\n",
        "            num_examples_to_show=config.get(\"num_examples_to_show\", 3)\n",
        "        )\n",
        "\n",
        "        evaluations, scores, average_score = evaluate_with_gpt4(\n",
        "            predictions=predictions,\n",
        "            ground_truths=ground_truths,\n",
        "            questions=questions,\n",
        "            num_examples_to_show=3,\n",
        "            max_eval_samples = 100)\n",
        "\n",
        "        return evaluations, scores, average_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ablation Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQksg90TdLHa"
      },
      "outputs": [],
      "source": [
        "ablation_configs = [\n",
        "    {\n",
        "        \"image_encoder_type\": \"swin\",\n",
        "        \"freeze_image_encoder\": False,\n",
        "        \"num_cross_attention_layers\": 2,\n",
        "        \"projection_size\": 512,\n",
        "        \"fusion_method\": \"add\",\n",
        "        \"include_caption\": True,\n",
        "        \"subset_size\": None,  # Use a smaller subset\n",
        "        \"epochs\": 20,\n",
        "        \"log_interval\": 100,\n",
        "        \"num_freeze_epochs\": 2,\n",
        "        \"num_examples_to_show\": 3\n",
        "    }\n",
        "    # {\n",
        "    #     \"image_encoder_type\": \"resnet\",\n",
        "    #     \"freeze_image_encoder\": False,\n",
        "    #     \"num_cross_attention_layers\": 1,\n",
        "    #     \"projection_size\": 256,\n",
        "    #     \"fusion_method\": \"concat\",\n",
        "    #     \"include_caption\": True,\n",
        "    #     \"subset_size\": 500,  # Even smaller subset\n",
        "    #     \"epochs\": 3,\n",
        "    #     \"log_interval\": 50,\n",
        "    #     \"num_freeze_epochs\": 1,\n",
        "    #     \"num_examples_to_show\": 2\n",
        "    # }\n",
        "    # Add more configurations as needed\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intialize the Model and Run Training/Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHN3aY7T4xvy"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\", padding_side=\"left\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O-YS_-CndquY",
        "outputId": "a0fdec45-9c56-422b-9250-f1ea7c55430c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Ablation Study 1 ====================\n",
            "Configuration: {'image_encoder_type': 'swin', 'freeze_image_encoder': False, 'num_cross_attention_layers': 2, 'projection_size': 512, 'fusion_method': 'add', 'include_caption': True, 'subset_size': None, 'epochs': 20, 'log_interval': 100, 'num_freeze_epochs': 2, 'num_examples_to_show': 3}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized Swin Transformer as image encoder.\n",
            "Image encoder parameters are trainable.\n",
            "Image projection layers initialized with projection size 512.\n",
            "Initialized cross-attention layer 1.\n",
            "Initialized cross-attention layer 2.\n",
            "Fusion method set to 'add'. No additional projection layer needed.\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-31-fa6722b8179c>:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()  # For mixed precision training\n",
            "Epoch 1:   0%|          | 0/795 [00:00<?, ?it/s]<ipython-input-31-fa6722b8179c>:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1:  13%|        | 100/795 [00:29<03:20,  3.47it/s, Average Loss=5.2136]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 5.2136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  25%|       | 200/795 [00:57<02:49,  3.51it/s, Average Loss=4.5862]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 4.5862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  38%|      | 300/795 [01:26<02:21,  3.51it/s, Average Loss=4.2901]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 4.2901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  50%|     | 400/795 [01:54<01:52,  3.51it/s, Average Loss=4.1229]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 4.1229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  63%|   | 500/795 [02:22<01:24,  3.50it/s, Average Loss=4.0095]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 4.0095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  75%|  | 600/795 [02:51<00:55,  3.49it/s, Average Loss=3.9315]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 3.9315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  88%| | 700/795 [03:19<00:27,  3.52it/s, Average Loss=3.8691]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 3.8691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=3.8691]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 completed. Average Loss: 3.8155\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2:  13%|        | 100/795 [00:28<03:16,  3.53it/s, Average Loss=3.3850]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 3.3850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  25%|       | 200/795 [00:57<02:48,  3.53it/s, Average Loss=3.3816]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 3.3816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  38%|      | 300/795 [01:25<02:20,  3.53it/s, Average Loss=3.3720]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 3.3720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  50%|     | 400/795 [01:53<01:51,  3.53it/s, Average Loss=3.3580]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 3.3580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  63%|   | 500/795 [02:22<01:23,  3.54it/s, Average Loss=3.3404]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 3.3404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  75%|  | 600/795 [02:50<00:56,  3.47it/s, Average Loss=3.3360]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 3.3360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  88%| | 700/795 [03:18<00:26,  3.54it/s, Average Loss=3.3307]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 3.3307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|| 795/795 [03:45<00:00,  3.52it/s, Average Loss=3.3307]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 completed. Average Loss: 3.3232\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3:  13%|        | 100/795 [00:29<03:16,  3.53it/s, Average Loss=3.1528]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 3.1528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  25%|       | 200/795 [00:57<02:48,  3.54it/s, Average Loss=3.1339]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 3.1339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  38%|      | 300/795 [01:26<02:20,  3.53it/s, Average Loss=3.1219]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 3.1219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  50%|     | 400/795 [01:54<01:51,  3.54it/s, Average Loss=3.1140]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 3.1140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  63%|   | 500/795 [02:22<01:23,  3.52it/s, Average Loss=3.1025]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 3.1025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  75%|  | 600/795 [02:51<00:55,  3.53it/s, Average Loss=3.0907]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 3.0907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  88%| | 700/795 [03:19<00:26,  3.52it/s, Average Loss=3.0786]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 3.0786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=3.0786]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 completed. Average Loss: 3.0639\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4:  13%|        | 100/795 [00:29<03:18,  3.50it/s, Average Loss=2.8099]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 2.8099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  25%|       | 200/795 [00:57<02:48,  3.53it/s, Average Loss=2.8006]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 2.8006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  38%|      | 300/795 [01:25<02:20,  3.52it/s, Average Loss=2.7823]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 2.7823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  50%|     | 400/795 [01:54<01:51,  3.53it/s, Average Loss=2.7767]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 2.7767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  63%|   | 500/795 [02:22<01:23,  3.54it/s, Average Loss=2.7612]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 2.7612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  75%|  | 600/795 [02:50<00:55,  3.54it/s, Average Loss=2.7540]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 2.7540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  88%| | 700/795 [03:19<00:26,  3.53it/s, Average Loss=2.7501]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 2.7501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|| 795/795 [03:46<00:00,  3.52it/s, Average Loss=2.7501]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 completed. Average Loss: 2.7423\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5:  13%|        | 100/795 [00:29<03:16,  3.53it/s, Average Loss=2.4907]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 2.4907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  25%|       | 200/795 [00:57<02:48,  3.53it/s, Average Loss=2.4819]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 2.4819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  38%|      | 300/795 [01:25<02:20,  3.52it/s, Average Loss=2.4772]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 2.4772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  50%|     | 400/795 [01:54<01:51,  3.53it/s, Average Loss=2.4799]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 2.4799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  63%|   | 500/795 [02:22<01:23,  3.54it/s, Average Loss=2.4742]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 2.4742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  75%|  | 600/795 [02:50<00:55,  3.52it/s, Average Loss=2.4715]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 2.4715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  88%| | 700/795 [03:19<00:26,  3.54it/s, Average Loss=2.4676]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 2.4676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=2.4676]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 completed. Average Loss: 2.4607\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6:  13%|        | 100/795 [00:28<03:16,  3.53it/s, Average Loss=2.2540]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 2.2540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  25%|       | 200/795 [00:57<02:48,  3.52it/s, Average Loss=2.2469]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 2.2469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  38%|      | 300/795 [01:25<02:20,  3.53it/s, Average Loss=2.2453]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 2.2453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  50%|     | 400/795 [01:54<01:51,  3.53it/s, Average Loss=2.2468]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 2.2468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  63%|   | 500/795 [02:22<01:23,  3.54it/s, Average Loss=2.2439]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 2.2439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  75%|  | 600/795 [02:50<00:55,  3.53it/s, Average Loss=2.2427]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 2.2427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  88%| | 700/795 [03:19<00:26,  3.54it/s, Average Loss=2.2373]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 2.2373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=2.2373]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 completed. Average Loss: 2.2368\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7:  13%|        | 100/795 [00:29<03:16,  3.54it/s, Average Loss=2.0349]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 2.0349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  25%|       | 200/795 [00:57<02:48,  3.53it/s, Average Loss=2.0472]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 2.0472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  38%|      | 300/795 [01:25<02:20,  3.53it/s, Average Loss=2.0443]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 2.0443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  50%|     | 400/795 [01:54<01:51,  3.54it/s, Average Loss=2.0440]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 2.0440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  63%|   | 500/795 [02:22<01:23,  3.53it/s, Average Loss=2.0397]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 2.0397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  75%|  | 600/795 [02:50<00:55,  3.53it/s, Average Loss=2.0442]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 2.0442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  88%| | 700/795 [03:19<00:26,  3.53it/s, Average Loss=2.0458]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 2.0458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|| 795/795 [03:46<00:00,  3.52it/s, Average Loss=2.0458]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 completed. Average Loss: 2.0468\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8:  13%|        | 100/795 [00:28<03:16,  3.54it/s, Average Loss=1.8721]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.8721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  25%|       | 200/795 [00:57<02:49,  3.52it/s, Average Loss=1.8738]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.8738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  38%|      | 300/795 [01:25<02:20,  3.53it/s, Average Loss=1.8810]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.8810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  50%|     | 400/795 [01:54<01:51,  3.53it/s, Average Loss=1.8856]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.8856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  63%|   | 500/795 [02:22<01:24,  3.48it/s, Average Loss=1.8811]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.8811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  75%|  | 600/795 [02:50<00:55,  3.51it/s, Average Loss=1.8817]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.8817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  88%| | 700/795 [03:19<00:27,  3.50it/s, Average Loss=1.8806]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.8806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.8806]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 completed. Average Loss: 1.8827\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9:  13%|        | 100/795 [00:29<03:19,  3.49it/s, Average Loss=1.7328]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.7328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  25%|       | 200/795 [00:57<02:49,  3.51it/s, Average Loss=1.7348]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.7348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  38%|      | 300/795 [01:25<02:20,  3.52it/s, Average Loss=1.7293]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.7293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  50%|     | 400/795 [01:54<01:51,  3.53it/s, Average Loss=1.7276]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.7276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  63%|   | 500/795 [02:22<01:24,  3.50it/s, Average Loss=1.7360]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.7360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  75%|  | 600/795 [02:50<00:55,  3.52it/s, Average Loss=1.7397]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.7397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  88%| | 700/795 [03:19<00:27,  3.51it/s, Average Loss=1.7386]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.7386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.7386]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 completed. Average Loss: 1.7392\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10:  13%|        | 100/795 [00:29<03:20,  3.47it/s, Average Loss=1.6079]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.6079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  25%|       | 200/795 [00:57<02:54,  3.40it/s, Average Loss=1.6054]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.6054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  38%|      | 300/795 [01:26<02:20,  3.52it/s, Average Loss=1.6085]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.6085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  50%|     | 400/795 [01:54<01:52,  3.51it/s, Average Loss=1.6116]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.6116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  63%|   | 500/795 [02:22<01:23,  3.53it/s, Average Loss=1.6117]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.6117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  75%|  | 600/795 [02:51<00:55,  3.52it/s, Average Loss=1.6146]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.6146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  88%| | 700/795 [03:19<00:27,  3.51it/s, Average Loss=1.6139]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.6139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.6139]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 completed. Average Loss: 1.6161\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11:  13%|        | 100/795 [00:29<03:19,  3.48it/s, Average Loss=1.4965]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.4965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11:  25%|       | 200/795 [00:57<02:50,  3.49it/s, Average Loss=1.4970]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.4970\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11:  38%|      | 300/795 [01:25<02:20,  3.52it/s, Average Loss=1.5002]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.5002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11:  50%|     | 400/795 [01:54<01:52,  3.50it/s, Average Loss=1.5045]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.5045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11:  63%|   | 500/795 [02:22<01:23,  3.52it/s, Average Loss=1.5071]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.5071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11:  75%|  | 600/795 [02:51<00:55,  3.51it/s, Average Loss=1.5074]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.5074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11:  88%| | 700/795 [03:19<00:27,  3.49it/s, Average Loss=1.5082]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.5082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.5082]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 completed. Average Loss: 1.5085\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12:  13%|        | 100/795 [00:28<03:16,  3.53it/s, Average Loss=1.3951]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.3951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12:  25%|       | 200/795 [00:57<02:48,  3.53it/s, Average Loss=1.4014]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.4014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12:  38%|      | 300/795 [01:25<02:21,  3.49it/s, Average Loss=1.4049]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.4049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12:  50%|     | 400/795 [01:53<01:52,  3.53it/s, Average Loss=1.4089]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.4089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12:  63%|   | 500/795 [02:22<01:23,  3.53it/s, Average Loss=1.4071]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.4071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12:  75%|  | 600/795 [02:50<00:55,  3.53it/s, Average Loss=1.4069]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.4069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12:  88%| | 700/795 [03:19<00:26,  3.52it/s, Average Loss=1.4119]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.4119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|| 795/795 [03:45<00:00,  3.52it/s, Average Loss=1.4119]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 completed. Average Loss: 1.4132\n",
            "\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13:  13%|        | 100/795 [00:29<03:17,  3.52it/s, Average Loss=1.3157]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.3157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13:  25%|       | 200/795 [00:57<02:48,  3.54it/s, Average Loss=1.3185]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.3185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13:  38%|      | 300/795 [01:25<02:20,  3.54it/s, Average Loss=1.3233]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.3233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13:  50%|     | 400/795 [01:53<01:52,  3.50it/s, Average Loss=1.3258]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.3258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13:  63%|   | 500/795 [02:22<01:23,  3.52it/s, Average Loss=1.3248]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.3248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13:  75%|  | 600/795 [02:50<00:55,  3.53it/s, Average Loss=1.3292]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.3292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13:  88%| | 700/795 [03:19<00:27,  3.51it/s, Average Loss=1.3327]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.3327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.3327]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 completed. Average Loss: 1.3344\n",
            "\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 14:  13%|        | 100/795 [00:28<03:16,  3.54it/s, Average Loss=1.2546]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.2546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14:  25%|       | 200/795 [00:57<02:48,  3.54it/s, Average Loss=1.2540]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.2540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14:  38%|      | 300/795 [01:25<02:20,  3.53it/s, Average Loss=1.2629]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.2629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14:  50%|     | 400/795 [01:54<01:52,  3.53it/s, Average Loss=1.2638]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.2638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14:  63%|   | 500/795 [02:22<01:23,  3.52it/s, Average Loss=1.2644]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.2644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14:  75%|  | 600/795 [02:51<00:55,  3.50it/s, Average Loss=1.2657]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.2657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14:  88%| | 700/795 [03:19<00:26,  3.54it/s, Average Loss=1.2671]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.2671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.2671]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 completed. Average Loss: 1.2684\n",
            "\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 15:  13%|        | 100/795 [00:28<03:17,  3.52it/s, Average Loss=1.2084]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.2084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15:  25%|       | 200/795 [00:57<02:48,  3.53it/s, Average Loss=1.2073]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.2073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15:  38%|      | 300/795 [01:25<02:19,  3.54it/s, Average Loss=1.2051]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.2051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15:  50%|     | 400/795 [01:53<01:51,  3.54it/s, Average Loss=1.2050]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.2050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15:  63%|   | 500/795 [02:22<01:23,  3.51it/s, Average Loss=1.2067]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.2067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15:  75%|  | 600/795 [02:50<00:55,  3.52it/s, Average Loss=1.2066]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.2066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15:  88%| | 700/795 [03:19<00:26,  3.52it/s, Average Loss=1.2082]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.2082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.2082]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 completed. Average Loss: 1.2092\n",
            "\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 16:  13%|        | 100/795 [00:29<03:17,  3.53it/s, Average Loss=1.1571]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.1571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16:  25%|       | 200/795 [00:57<02:48,  3.53it/s, Average Loss=1.1524]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.1524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16:  38%|      | 300/795 [01:25<02:22,  3.48it/s, Average Loss=1.1511]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.1511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16:  50%|     | 400/795 [01:54<01:52,  3.52it/s, Average Loss=1.1527]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.1527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16:  63%|   | 500/795 [02:22<01:23,  3.54it/s, Average Loss=1.1556]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.1556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16:  75%|  | 600/795 [02:51<00:55,  3.54it/s, Average Loss=1.1567]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.1567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16:  88%| | 700/795 [03:19<00:27,  3.52it/s, Average Loss=1.1581]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.1581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.1581]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 completed. Average Loss: 1.1587\n",
            "\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 17:  13%|        | 100/795 [00:29<03:17,  3.52it/s, Average Loss=1.1115]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.1115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17:  25%|       | 200/795 [00:57<02:48,  3.52it/s, Average Loss=1.1088]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.1088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17:  38%|      | 300/795 [01:26<02:20,  3.52it/s, Average Loss=1.1142]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.1142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17:  50%|     | 400/795 [01:54<01:52,  3.52it/s, Average Loss=1.1158]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.1158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17:  63%|   | 500/795 [02:22<01:23,  3.53it/s, Average Loss=1.1202]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.1202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17:  75%|  | 600/795 [02:51<00:55,  3.53it/s, Average Loss=1.1206]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.1206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17:  88%| | 700/795 [03:19<00:26,  3.54it/s, Average Loss=1.1193]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.1193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.1193]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 completed. Average Loss: 1.1191\n",
            "\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 18:  13%|        | 100/795 [00:28<03:16,  3.53it/s, Average Loss=1.0846]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.0846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18:  25%|       | 200/795 [00:57<02:48,  3.54it/s, Average Loss=1.0880]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.0880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18:  38%|      | 300/795 [01:25<02:20,  3.53it/s, Average Loss=1.0827]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.0827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18:  50%|     | 400/795 [01:53<01:52,  3.52it/s, Average Loss=1.0817]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.0817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18:  63%|   | 500/795 [02:22<01:23,  3.53it/s, Average Loss=1.0811]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.0811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18:  75%|  | 600/795 [02:50<00:55,  3.53it/s, Average Loss=1.0833]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.0833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18:  88%| | 700/795 [03:18<00:27,  3.51it/s, Average Loss=1.0853]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.0853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18: 100%|| 795/795 [03:45<00:00,  3.52it/s, Average Loss=1.0853]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 completed. Average Loss: 1.0864\n",
            "\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 19:  13%|        | 100/795 [00:28<03:22,  3.44it/s, Average Loss=1.0672]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.0672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19:  25%|       | 200/795 [00:57<02:48,  3.52it/s, Average Loss=1.0652]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.0652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19:  38%|      | 300/795 [01:25<02:20,  3.52it/s, Average Loss=1.0615]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.0615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19:  50%|     | 400/795 [01:54<01:52,  3.50it/s, Average Loss=1.0618]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.0618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19:  63%|   | 500/795 [02:22<01:24,  3.49it/s, Average Loss=1.0612]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.0612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19:  75%|  | 600/795 [02:51<00:55,  3.50it/s, Average Loss=1.0607]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.0607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19:  88%| | 700/795 [03:19<00:26,  3.53it/s, Average Loss=1.0593]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.0593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.0593]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 completed. Average Loss: 1.0594\n",
            "\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 20:  13%|        | 100/795 [00:28<03:16,  3.53it/s, Average Loss=1.0423]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/795] - Loss: 1.0423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20:  25%|       | 200/795 [00:57<02:48,  3.52it/s, Average Loss=1.0448]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [200/795] - Loss: 1.0448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20:  38%|      | 300/795 [01:26<02:21,  3.49it/s, Average Loss=1.0426]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [300/795] - Loss: 1.0426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20:  50%|     | 400/795 [01:54<01:52,  3.52it/s, Average Loss=1.0447]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [400/795] - Loss: 1.0447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20:  63%|   | 500/795 [02:22<01:24,  3.50it/s, Average Loss=1.0462]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/795] - Loss: 1.0462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20:  75%|  | 600/795 [02:51<00:56,  3.47it/s, Average Loss=1.0456]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [600/795] - Loss: 1.0456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20:  88%| | 700/795 [03:19<00:26,  3.53it/s, Average Loss=1.0441]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [700/795] - Loss: 1.0441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20: 100%|| 795/795 [03:46<00:00,  3.51it/s, Average Loss=1.0441]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 completed. Average Loss: 1.0435\n",
            "\n",
            "Training completed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   1%|          | 1/175 [00:01<03:46,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample 1:\n",
            "Question: What does the image depict about the patient's tumor? \n",
            "Prediction: Lung lung disappeared relapsed runk.\n",
            "Ground Truth: The tumor has shrunk\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating:   1%|          | 2/175 [00:01<02:29,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample 2:\n",
            "Question: What is the location of the lesion described in the axial slice? \n",
            "Prediction: Right right tibia.\n",
            "Ground Truth: Upper right maxilla\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating:   2%|         | 3/175 [00:02<02:04,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample 3:\n",
            "Question:  What veins are visible in the abdominal CT scan at the level of line? \n",
            "Prediction: Right to vena duodenal vein (right portal epiploic vein.\n",
            "Ground Truth: Anterior superior pancreaticoduodenal vein and right gastroepiploic vein\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 175/175 [01:37<00:00,  1.79it/s]\n",
            "1it [00:02,  2.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the name of the condition shown in the image? \n",
            "Groud Truth is:  Colloid cyst\n",
            "Prediction is:  Cpcyst of\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Cpcyst of,\" does not provide a clear or relevant response to the medical question. The intended answer, \"Colloid cyst,\" is not recognizable in the model's response. The model's answer contains jumbled characters and lacks any key information related to the correct answer. Consequently, it fails to meet any of the criteria for helpfulness, relevance, or clarity in this context.\n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r2it [00:04,  2.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of ultrasound image is shown in the caption? \n",
            "Groud Truth is:  3D ultrasound image\n",
            "Prediction is:  Ultrasound ultrasound image.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Ultrasound ultrasound image,\" is neither clear nor helpful in identifying the type of ultrasound image specified in the question. It simply repeats the word \"ultrasound\" without providing any relevant information. The correct answer involved specifying that it is a 3D ultrasound image, which the model failed to do. There is no key information provided in the response, and it does not offer any clarity or relevance to the question asked.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r3it [00:07,  2.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the condition of the tumor observed in the CT scan? \n",
            "Groud Truth is:  Benign with no serosal invasion\n",
            "Prediction is:  CT tumor no evidence invasion,\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"CT tumor no evidence invasion,\" accurately conveys the key information that there is no evidence of invasion, which pertains to the assessment of the tumor's condition. While the answer lacks clarity and completeness due to its brevity and lack of specificity (it does not explicitly mention whether the tumor is benign), it captures a critical aspect of the original answer concerning the absence of serosal invasion. The response would benefit from a more complete sentence and the inclusion of the term \"benign\" to enhance clarity and relevance.\n",
            "\n",
            "Rating: 6/10\n",
            "Numeric Score: 0.60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r4it [00:09,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What staining method is used in the bottom row of images? \n",
            "Groud Truth is:  Male staining\n",
            "Prediction is:  Nile izn,\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Nile izn,\" does not provide a relevant or correct response to the question about which staining method is used in the bottom row of images. The correct answer is \"Male staining,\" and the provided answer does not include any useful or key information related to this. While it may have been an attempt at generating relevant content, the response lacks clarity and does not closely resemble the correct answer.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r5it [00:11,  2.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the subject of the 3D rendering? \n",
            "Groud Truth is:  Uterus\n",
            "Prediction is:  Uterine us tissue\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Uterine us tissue,\" is quite close to the correct answer, \"Uterus.\" However, it includes an unnecessary and confusing term, \"us,\" which could be a typographical error intending to say \"uterus tissue\" or otherwise unintended. Despite this, it still communicates the primary subject fairly well by including the key term \"uterine,\" which relates to the uterus. The additional characters and words slightly reduce the clarity but the overall meaning is generally preserved. Given that the model's response depicts the correct anatomical area related to the uterus, it shows a high level of relevance. It avoids overly detailed or irrelevant information, staying quite close to a correct response.\n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r6it [00:16,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the main parameter being measured in the map shown in panel F? \n",
            "Groud Truth is:  Blood flow\n",
            "Prediction is:  Normal flow maps\n",
            "GPT-4 Evaluation:\n",
            " The models answer, \"Normal flow maps,\" lacks clarity and relevance to the original question. It does not directly address the main parameter being measured in panel F, which is \"blood flow.\" The term \"normal flow maps\" implies a type of map but doesn't specify what is being measured, nor does it directly relate to \"blood flow.\" The response is not sufficiently clear or helpful in this context. Because it does not include the key information about what is actually being measured, the model's response is not particularly informative. \n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r7it [00:19,  3.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the condition shown in the image? \n",
            "Groud Truth is:  Atrioventricular septal defect\n",
            "Prediction is:  Mitral treoventricular valve defect and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Mitral treoventricular valve defect and,\" is not clear or complete. Firstly, it appears to contain a typographical error, \"treoventricular,\" which is likely intended to mean \"atrioventricular.\" However, the answer still does not accurately describe the condition shown in the image, which is an atrioventricular septal defect (AVSD). This defect includes issues with both the atrial septum and ventricular septum as well as abnormalities in the atrioventricular valves. \n",
            "\n",
            "The model's answer partially touches upon the involvement of a valve, which is relevant to AVSD, but it fails to clearly communicate the condition. The incomplete sentence and the typographical error significantly reduce the clarity and helpfulness of the response. While it does attempt to address the valve involvement, it lacks precision and relevance to the correct medical condition.\n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r8it [00:21,  2.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What technique is used for macroscopic observation of nerve roots postoperatively? \n",
            "Groud Truth is:  Endoscope\n",
            "Prediction is:  X cope.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"X cope,\" is unclear and does not provide the correct or relevant information related to the technique used for macroscopic observation of nerve roots postoperatively. It seems to be an incomplete or incorrect word and does not effectively communicate the intended response. The correct technique is an \"endoscope,\" which is not represented in the model's answer. Therefore, the response lacks helpfulness, relevance, and clarity. \n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r9it [00:24,  2.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the staining used in the image? \n",
            "Groud Truth is:  Hematoxylin eosin staining\n",
            "Prediction is:  Hematoxylin and eosin staining and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Hematoxylin and eosin staining and\", is very close to the correct answer of \"Hematoxylin eosin staining.\" The inclusion of the word \"and\" at the end is extraneous but does not detract significantly from the relevance or helpfulness of the information provided. The key information offered, which is the type of staining used, is accurate and clear. Overall, the answer is relevant and sufficiently meets the question's requirement, despite the unnecessary ending.\n",
            "\n",
            "Rating: 9/10\n",
            "Numeric Score: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r10it [00:26,  2.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the marker clip seen on the mammogram? \n",
            "Groud Truth is:  A foreign object\n",
            "Prediction is:  Botmammbody in\n",
            "GPT-4 Evaluation:\n",
            " The models answer, \"Botmammbody in,\" does not provide a clear or relevant response to the question about a marker clip seen on a mammogram. There is no coherent or medically relevant information presented, and it lacks any helpful or correct detail about what a marker clip is in the context of a mammogram. The inclusion of random characters and words does not contribute any valuable information, thus failing to answer the question adequately.\n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r11it [00:29,  2.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of fracture was found in the pre-operative CT scan? \n",
            "Groud Truth is:  Stress fracture\n",
            "Prediction is:  Type fracture in\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Type fracture in,\" lacks clarity, relevance, and helpfulness. It does not provide any meaningful or correct information related to the question about the type of fracture found on the pre-operative CT scan, which is a stress fracture. The response does not offer any useful content and does not come close to the correct answer. \n",
            "\n",
            "The model's response does not include any correct or partial key information. Consequently, the answer does not meet the expectations for a helpful response in this context.\n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r12it [00:34,  3.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the focus of the section shown in the image? \n",
            "Groud Truth is:  The nuclear plane\n",
            "Prediction is:  Confocal equatorial level.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Confocal equatorial level,\" does not precisely match the correct answer, \"The nuclear plane.\" The term \"confocal\" refers to a technique used in certain types of microscopy, and \"equatorial level\" could suggest a central or balanced focus, but these terms collectively do not substitute for \"nuclear plane.\" While the provided answer does contain elements that could be relevant in a broader microscopy or histological context, it lacks clarity and direct relevance to the specific question asked. Therefore, it offers limited helpfulness. However, since it is somewhat close due to its scientific terminology, it deserves some credit for attempting an educated guess.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r13it [00:37,  3.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What types of mammogram images are used in breast cancer screening? \n",
            "Groud Truth is:  Bilateral craniocaudal and mediolateral oblique.\n",
            "Prediction is:  Mambreast audal views mediolateral mammograms views\n",
            "GPT-4 Evaluation:\n",
            " The model's answer attempts to provide the types of mammogram images used in breast cancer screening, but it is unclear and contains typographical errors. While it mentions \"mediolateral,\" which is part of the correct term \"mediolateral oblique,\" it fails to accurately convey the full names of the standard views, \"bilateral craniocaudal\" and \"mediolateral oblique.\" The use of incorrect or misspelled terms such as \"mambreast\" and \"audal\" detracts from the clarity and professionalism of the response. Therefore, while the answer contains one key piece of information, it is not sufficiently accurate or clear to be considered helpful or relevant.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r14it [00:41,  3.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   From which two retinal areas were color fundus photographs obtained? \n",
            "Groud Truth is:  Peripheral and superior retina\n",
            "Prediction is:  Superior retina superior temporal.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Superior retina superior temporal,\" partially addresses the question by mentioning the \"superior retina.\" However, it omits \"peripheral retina,\" which is also part of the correct answer. The inclusion of \"superior temporal\" introduces an additional, less relevant detail that may confuse the response. While it captures one of the required areas, the lack of mention of the peripheral retina results in incomplete information. It is important for the answer to clearly specify both required areas to be fully helpful and relevant.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r15it [00:44,  3.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What type of scan was used in the image fusion? \n",
            "Groud Truth is:  CT and MRI scans\n",
            "Prediction is:  T1 scan MRI scan.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"T1 scan MRI scan,\" provides partial information regarding the type of scan used in the image fusion. It correctly identifies the use of an MRI scan, specifying a T1-weighted MRI, which is relevant information. However, it misses mentioning the use of a CT scan, which is also part of the correct answer. \n",
            "\n",
            "The response is somewhat helpful and relevant, as it identifies one of the imaging modalities involved but lacks completeness. In terms of clarity, the phrase \"T1 scan MRI scan\" could be slightly confusing due to repetition and lack of context.\n",
            "\n",
            "Despite these issues, the answer does include at least one key piece of information, therefore it deserves partial credit but does not fully answer the question posed.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r16it [00:47,  3.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What are the three directions represented in the images?\n",
            "Groud Truth is:  dorsal, ventral, medial;\n",
            "Prediction is:  Vand lateral, and, and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is unclear and contains errors. It misidentifies the directions and provides a nonsensical list (\"Vand lateral, and, and\") instead of the correct anatomical terms (\"dorsal, ventral, medial\"). There is no indication of understanding or relevance in the response, as it does not match any part of the correct answer. \n",
            "\n",
            "Despite needing improvements, since the model attempted to mention \"lateral\" which is an anatomical direction (albeit not from the correct list), some partial credit might be given for proximity to relevant terms.  \n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r17it [00:49,  3.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the red star indicating in the image? \n",
            "Groud Truth is:  A mature air pore\n",
            "Prediction is:  The sensifruit-.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"The sensifruit-,\" does not provide any relevant or clear information related to the question about what the red star indicates in the image. There is no connection between \"sensifruit-\" and a \"mature air pore,\" which is the correct answer. The response lacks key information and does not contribute any understanding to the query. Therefore, it falls short in terms of helpfulness and relevance. \n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r18it [00:52,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  Where is the lesion located? \n",
            "Groud Truth is:  C2\n",
            "Prediction is:  C5-\n",
            "GPT-4 Evaluation:\n",
            " The model's answer \"C5-\" is incorrect in identifying the lesion location, which was correctly answered as \"C2.\" While the answer is related to spinal segment identification, it doesn't provide the correct location or convey any key information regarding the question asked. The presence of the additional character \"-\" does not add value, clarity, or relevance. Overall, the model's response lacks helpfulness, relevance, and clarity, as it fails to provide the correct answer or any part of it. \n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r19it [00:55,  3.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which part of the eye is represented by sample c in the histopathological analysis? \n",
            "Groud Truth is:  Retina\n",
            "Prediction is:  Normal tina and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Normal tina and,\" appears to be an incomplete and incorrect representation of the correct answer, which is \"Retina.\" The response lacks clarity and relevance as it neither identifies the correct part of the eye nor provides a coherent contribution to the question. There is no discernible key information present in the model's response, so it does not meet the criteria for at least half the score, which would require some relevant information to be present. Despite the response being close in terms of phonetic sound at the beginning (\"tina\" resembling \"retina\"), it does not accurately convey the intended meaning or concept required to answer the question.\n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r20it [00:58,  3.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What did the imaging suggest was causing the chest pain? \n",
            "Groud Truth is:  Critical narrowing or occlusion of the left anterior descending coronary artery\n",
            "Prediction is:  Left stenosis in occlusion of the left anterior descending artery artery in\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is reasonably helpful and relevant, addressing the key information required to respond to the question. It clearly identifies the left anterior descending artery as involved, which is critical to understanding the context of the chest pain. However, the wording is somewhat awkward (\"Left stenosis in occlusion of the left anterior descending artery artery in\"), and there is a repetition of the word \"artery,\" which impacts clarity. Despite this, the model's response effectively communicates the essential idea, aligning closely with the correct answer. Overall, while there's room for improvement in terms of clarity, the response sufficiently conveys the necessary information.\n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r21it [01:01,  2.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the staining method used in the image? \n",
            "Groud Truth is:  Masson Trichrome Stain\n",
            "Prediction is:  Masson's rome staining tain.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Masson's rome staining tain,\" is close to the correct answer but contains typographical errors. It demonstrates an understanding of the staining method by including the term \"Masson\" and an attempt at \"Trichrome,\" which indicates some recognition of the correct method. However, clarity is compromised due to these errors, which could lead to confusion. It doesn't perfectly match \"Masson Trichrome Stain,\" but acknowledges the key element, which is \"Masson\". Although it lacks precision, it possesses part of the relevant information. \n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r22it [01:04,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What do the red and green dots represent in the radiographs? \n",
            "Groud Truth is:  The centers of the metatarsal bone.\n",
            "Prediction is:  Medial length of the metatarsal heads I\n",
            "GPT-4 Evaluation:\n",
            " The model's answer does not correctly address the question about what the red and green dots represent in the radiographs. The provided answer mentions \"Medial length of the metatarsal heads I,\" which does not relate to the centers of the metatarsal bone. The response lacks relevance to the original question, as it does not mention the centers of the metatarsal bones or explain what the dots signify meaningfully. \n",
            "\n",
            "While the answer includes terms related to metatarsal anatomy, it diverges significantly from the correct interpretation. Therefore, the clarity and helpfulness of the response are limited. A closer approximation to the correct answer is needed to warrant a higher score.\n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r23it [01:05,  2.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of imaging was used to assess the acetabular fracture after surgery? \n",
            "Groud Truth is:  CT scan\n",
            "Prediction is:  CT scan.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"CT scan,\" directly matches the correct answer provided for the question. It is concise, relevant, and clear, addressing the specific type of imaging used to assess the acetabular fracture after surgery without unnecessary elaboration. Therefore, it effectively satisfies all the criteria of helpfulness, relevance, and clarity.\n",
            "\n",
            "Rating: 10/10\n",
            "Numeric Score: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r24it [01:07,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the likely diagnosis for the described lesion? \n",
            "Groud Truth is:  Meningioma\n",
            "Prediction is:  Hyperioma and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Hyperioma and\", is not relevant or helpful to the question. The term \"Hyperioma\" is not a recognized medical condition or diagnosis, suggesting a possible misunderstanding or error in the model's response. The answer does not provide any key information that aligns with the correct diagnosis of \"Meningioma.\" Due to the complete lack of relevance and helpfulness in addressing the question, the evaluation of the model's answer can only reflect the absence of any pertinent information or clarity.\n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r25it [01:14,  3.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the location of the metastasis shown in the MRI image? \n",
            "Groud Truth is:  thoracic vertebrae\n",
            "Prediction is:  Thoracic spine 1\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Thoracic spine 1,\" refers to a specific vertebra within the thoracic spine segment, which is closely related to the given correct answer, \"thoracic vertebrae.\" The model's response is relevant as it indicates a location within the thoracic region of the spine, and it provides a specific vertebra (the first thoracic vertebra, T1). While it is slightly less general than the correct answer, it still contains key information about the general location within the thoracic area, which is pertinent to the question.\n",
            "\n",
            "The response is helpful in that it identifies the thoracic spinal region, which matches the context of the question. However, the use of \"Thoracic spine 1\" might lead to some confusion if misinterpreted as referring specifically to only one vertebra rather than the general thoracic vertebrae region, but it still points the reader in the correct direction.\n",
            "\n",
            "Overall, the answer is relevant and clear, containing the essential information needed to identify the location of the metastasis, though it could be misinterpreted as overly specific.\n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r26it [01:16,  3.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of custard is shown in the image? \n",
            "Groud Truth is:  Alkaline acorn starch custard\n",
            "Prediction is:  St@-@ acia n starch film ard.\n",
            "GPT-4 Evaluation:\n",
            " The model's response, \"St@-@ acia n starch film ard,\" is not helpful, relevant, or clear in identifying the type of custard in the image. The answer does not contain any key information that corresponds to the correct answer, \"Alkaline acorn starch custard.\" The response seems to be a nonsensical string of characters and words without any meaningful content. It fails to convey any component of the correct answer. Thus, it is not possible to assign a score of at least half in this case as there is no recognizable link to the correct answer.\n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r27it [01:19,  3.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What type of cell is the cross-section shown in the image most likely from? \n",
            "Groud Truth is:  Muscle cell\n",
            "Prediction is:  Muscle cells fibers\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Muscle cells fibers,\" is largely accurate but slightly awkward in phrasing. It likely meant to convey \"muscle cell fibers\" or \"muscle fibers,\" which are indeed related to muscle cells and an appropriate response to the question. The inclusion of the term \"fibers\" suggests an understanding of the structure of muscle cells, which are often referred to as muscle fibers due to their elongated shape.\n",
            "\n",
            "Helpfulness: The answer directly addresses the question and seems to be identifying muscle cell structure correctly, given that muscle fibers are a common way to refer to muscle cells.\n",
            "Relevance: The answer stays on topic and connects well to what was asked.\n",
            "Clarity: The phrase could be clearer, primarily due to the redundant pluralization, but the core idea is still conveyed.\n",
            "\n",
            "Overall, while the response could be slightly improved in phrasing for clarity, it communicates the necessary information effectively.\n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r28it [01:21,  2.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of imaging was used to produce the image shown? \n",
            "Groud Truth is:  MRI\n",
            "Prediction is:  CT scan\n",
            "GPT-4 Evaluation:\n",
            " The model's answer \"CT scan\" is incorrect as the correct imaging type for the question is \"MRI.\" The response lacks helpfulness and relevance because it fails to provide the correct type of imaging. Clarity is satisfactory in that the response is concise, but it is misleading since it is inaccurate. There is no key information provided that aligns with the correct answer, therefore it does not score well in terms of helpfulness. \n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r29it [01:23,  2.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What are the yellow arrowheads indicating in the image? \n",
            "Groud Truth is:  formation of semilunar valves\n",
            "Prediction is:  Lymphof lymphoid itunar lymphatic and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is unclear, lacks relevance, and does not address the question adequately. It neither mentions the semilunar valves nor provides any helpful information related to the correct answer. The additional text \"Lymphof lymphoid itunar lymphatic and\" is not related to the formation of semilunar valves, which is the key information required to answer the question correctly. Given these shortcomings, the response does not deserve a high score. \n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r30it [01:26,  2.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the condition being shown in the image? \n",
            "Groud Truth is:  Age-related macular degeneration\n",
            "Prediction is:  Macular-related macular degeneration (\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is \"macular-related macular degeneration (\". This response is attempting to identify the condition as macular degeneration, which is indeed the correct general category. However, the answer is not fully accurate as the condition specified in the question is \"age-related macular degeneration.\" The model's response also ends with an incomplete phrase, suggesting the possibility of an unfinished thought or typographical error. \n",
            "\n",
            "While the model's response is in the right direction by identifying \"macular degeneration,\" it lacks precision and clarity. Yet, it is related to the correct answer, as it identifies the macular aspect of the condition. Therefore, it offers at least a partial recognition of the key information required.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r31it [01:28,  2.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What part of the femur did the tumors occur? \n",
            "Groud Truth is:  Proximal part\n",
            "Prediction is:  Proximal femur of\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Proximal femur of,\" includes the key information that the tumors occur in the \"proximal\" part of the femur. While the structure of the response is slightly incomplete due to the dangling \"of,\" it still effectively communicates the primary location being asked about. The answer is relevant and mostly clear in identifying that the tumors occur in the proximal part of the femur. Given that it contains the crucial information needed to answer the question, it meets the requirements for a good understanding of the question. Thus, it deserves a reasonable score.\n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r32it [01:30,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which type of imaging is not shown in the image provided?\n",
            "Groud Truth is:  Cranial enhanced CT\n",
            "Prediction is:  CT CT CT scan\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"CT CT CT scan,\" unfortunately lacks helpfulness, clarity, and relevance. It doesn't effectively communicate which type of imaging is not shown in the image. Repetition of \"CT\" does not contribute to clarity and may confuse the reader. The model should directly state the specific type of CT scan that is missing or not shown. It is not close to the correct answer, \"Cranial enhanced CT,\" and therefore does not meet the criteria for a good score, as it fails to include any key information.\n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r33it [01:34,  2.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the imaging and anatomical position used for body surface marking? \n",
            "Groud Truth is:  CT scan and prone position\n",
            "Prediction is:  X scan image 3D position.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"X scan image 3D position,\" lacks clarity and specificity in addressing the question. It does not mention CT scan or the prone position, which are the key components of the correct answer. The model's response appears to be vague and somewhat random, without providing any helpful or relevant information related to the topic of imaging and anatomical positions used for body surface marking.\n",
            "\n",
            "While the model's answer does hint at something related to scanning and position with the words \"scan\" and \"3D position,\" it does not effectively convey the correct information or relate directly to the specific query. \n",
            "\n",
            "Overall, the model's response falls short in helpfulness, clarity, and relevance, and fails to provide any of the key information needed to answer the question correctly.\n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r34it [01:36,  2.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the imaging modality used to visualize the mass in the left buccal region? \n",
            "Groud Truth is:  MRI\n",
            "Prediction is:  MRI scan\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"MRI scan,\" is accurate and relevant, as it correctly identifies the imaging modality used to visualize the mass in the left buccal region. The addition of the word \"scan\" does not detract from the clarity or helpfulness of the response, as it reinforces that MRI refers to an imaging technique. The answer is clear and directly addresses the question without unnecessary details. Overall, the response is both correct and concise, aligning closely with the correct answer.\n",
            "\n",
            "Rating: 10/10\n",
            "Numeric Score: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r35it [01:46,  4.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is being compared in the image? \n",
            "Groud Truth is:  Results of brain tumor segmentation\n",
            "Prediction is:  Brain of a scans segmentation on\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Brain of a scans segmentation on,\" is attempting to address the question regarding what is being compared in the image. However, the response lacks clarity and the necessary detail to convey that it is about the results of brain tumor segmentation. It includes some relevant terms, such as \"Brain\" and \"segmentation,\" which suggest it is on the topic of medical imaging analysis, but it doesn't effectively convey the complete concept of \"brain tumor segmentation.\" The phrase structure is incoherent, making it difficult to accurately interpret the intended message.\n",
            "\n",
            "The answer does contain at least one key piece of information pertinent to the desired answer, specifically the term \"segmentation,\" which is integral to understanding the focus of the comparison. However, the lack of coherence and specificity detracts considerably from the overall helpfulness and relevance to the original question.\n",
            "\n",
            "In light of these observations, while acknowledging the presence of a critical term, the response falls short in terms of clarity and precision.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r36it [01:49,  4.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which vertebrae are affected? \n",
            "Groud Truth is:  L4-L5\n",
            "Prediction is:  L4-L5 disc\n",
            "GPT-4 Evaluation:\n",
            " The model's answer \"L4-L5 disc\" captures the key information about the specific vertebrae affected, which are L4-L5. However, the term \"disc\" could imply additional context related to disc issues, which is not explicitly asked in the question that focuses on which vertebrae are affected. Despite this slight deviation, the answer still directly addresses the question by identifying the correct vertebrae. The mention of \"disc\" does not obscure the core information, making the response relevant, relatively clear, and helpful for understanding which vertebrae are involved. \n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r37it [01:51,  3.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which organ is located anterior to the large encapsulated collection observed on the CT scan? \n",
            "Groud Truth is:  Pancreas\n",
            "Prediction is:  Stomas and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer \"Stomas and\" does not provide relevant or clear information in response to the question about organ location based on a CT scan. The correct organ in question is the pancreas, and the response given fails to address this or provide any related anatomical reference. The term \"stomas\" is unrelated to the context of organ placement and encapsulated collections in a CT scan, leading to confusion rather than clarity. As such, the response neither provides useful information nor answers the question in a meaningful way. \n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r38it [01:54,  3.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the imaging finding described in the caption? \n",
            "Groud Truth is:  Heterogeneous bright signal\n",
            "Prediction is:  Hemorrhage hyposignal in\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Hemorrhage hyposignal in,\" is incomplete and does not directly align with the correct answer, \"Heterogeneous bright signal.\" The key term \"hyposignal\" is incorrect as it contradicts the \"bright signal\" part of the correct answer. Furthermore, the phrase is incomplete and lacks necessary context to be helpful. The model's response does not capture the main feature described in the correct answer.\n",
            "\n",
            "While there might be an attempt to identify a signal characteristic in imaging, the response does not provide the correct or complete information needed to evaluate the finding accurately. The answer lacks relevance and clarity, and therefore does not adequately address the question.\n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r39it [02:00,  4.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which muscle is affected according to the CT scan? \n",
            "Groud Truth is:  Oblique abdominal muscle\n",
            "Prediction is:  Right turmuscle muscle on\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Right turmuscle muscle on,\" does not convey clear or relevant information regarding the affected muscle in the context of the CT scan. There appears to be a misunderstanding or miscommunication in the response with invented terms such as \"turmuscle.\" As a result, the answer fails to identify the correct muscle, \"oblique abdominal muscle.\" The response lacks clarity and alignment with the question's requirements.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r40it [02:04,  3.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which parts of the arm are visible in the preoperative X-ray? \n",
            "Groud Truth is:  The proximal humerus, the middle shaft, and the supra condylar fracture.\n",
            "Prediction is:  Proximal humerus humerus. distal clavicle humerus and and the distal-area.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer attempts to address the question, but it contains errors and lacks clarity. The phrase \"Proximal humerus humerus\" is repetitive and unclear. It incorrectly mentions the \"distal clavicle,\" which is not a part of the arm typically visible in an X-ray focused on the humerus. The mention of \"distal-area\" is also vague and not consistent with the expected parts in the context of an arm X-ray. However, it does mention the \"proximal humerus,\" which is partly correct. \n",
            "\n",
            "To improve, the response should accurately include the areas: proximal humerus, middle shaft, and supra condylar area/fracture. This would make it more relevant and helpful. Given that the model includes one key part of the correct answer but has several inaccuracies and lacks clarity, it receives partial credit.\n",
            "\n",
            "Rating: 4/10\n",
            "Numeric Score: 0.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r41it [02:06,  3.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the finding in the abdominal ultrasound? \n",
            "Groud Truth is:  Increased liver size and multiple hypoechoic masses observed\n",
            "Prediction is:  Liver echogenicity size with heterogeneous hypoechoic nodules in in\n",
            "GPT-4 Evaluation:\n",
            " The model's answer partially conveys key information relevant to the ultrasound findings but lacks clarity and completeness. The mention of \"heterogeneous hypoechoic nodules\" somewhat aligns with \"multiple hypoechoic masses,\" which is a critical element of the correct answer. However, the response is marred by incomplete and unclear phrasing like \"liver echogenicity size,\" which muddles the intended message. Even though it suggests abnormalities in the liver, it doesn't clearly articulate the observation of increased liver size. Improving the overall coherence and directly addressing both \"increased liver size\" and the nature of the hypoechoic masses would enhance relevance and clarity.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r42it [02:08,  3.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Is there a thrombus inside the PA branch in (B)? \n",
            "Groud Truth is:  No\n",
            "Prediction is:  The blood\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"The blood,\" is completely unrelated to the question about the presence of a thrombus inside the PA (pulmonary artery) branch. It fails to address the key issue of whether there is a thrombus present and lacks any helpful, relevant, or clear information. The answer does not convey any of the correct information that would provide a suitable response to the question.\n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r43it [02:13,  3.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What channel was used for obtaining the images? \n",
            "Groud Truth is:  Porphyrazine fluorescence channel\n",
            "Prediction is:  Proyrria fluorescence..\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Proyrria fluorescence,\" is quite close to the correct answer, \"Porphyrazine fluorescence channel.\" The model's attempt demonstrates an understanding of the concept but has a minor error in the spelling of \"Porphyrazine,\" written as \"Proyrria.\" Despite this misspelling, the response is relevant to the question and conveys the key information of a fluorescence channel being used, albeit with an incorrect name.\n",
            "\n",
            "The answer is not entirely clear due to the spelling error, which could lead to some confusion if someone unfamiliar with the terminology attempted to use or understand the model's response. Nonetheless, the model captures the main idea, providing a response close to what is required.\n",
            "\n",
            "Overall, the model's answer is helpful and relevant but lacks clarity due to the misspelling. It includes the key information, which could be recognized with context in a medical setting, albeit imperfectly.\n",
            "\n",
            "Rating: 6/10\n",
            "Numeric Score: 0.60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r44it [02:16,  3.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What does the abnormality in the macular area consist of in the patient? \n",
            "Groud Truth is:  Subretinal detachment\n",
            "Prediction is:  Retinal bretinal fluid,\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Retinal bretinal fluid,\" attempts to address the question but contains a typographical error with the word \"bretinal\" which doesn't contribute to clarity or relevance. However, it does mention \"fluid,\" which is related to the concept of subretinal detachment, where fluid accumulates under the retina. Although the model's response is not clear and contains inaccuracies, it touches on a pertinent aspect of the condition.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r45it [02:19,  3.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What surgical procedure did the patient undergo before the standing AP radiograph? \n",
            "Groud Truth is:  Tibiotalocalcaneal arthrodesis surgery\n",
            "Prediction is:  Arthroia oplasty alocalcaneal Arthrowas with\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Arthroia oplasty alocalcaneal Arthrowas with,\" does not clearly convey the correct procedure, which is \"Tibiotalocalcaneal arthrodesis surgery.\" The response appears to be jumbled and lacks coherence, containing invented terms and a distorted version of the medical procedure name. There is no indication that the correct surgical procedure was acknowledged or partially captured by the answer. Thus, it fails to meet expectations in terms of relevance, helpfulness, and clarity. Despite the attempt, it does not provide any key information accurately.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r46it [02:23,  3.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the algorithm used in the CT scan images? \n",
            "Groud Truth is:  Bone\n",
            "Prediction is:  CT window\n",
            "GPT-4 Evaluation:\n",
            " The model's answer \"CT window\" is partially relevant. In CT imaging, different window settings (e.g., bone window, soft tissue window) are used to optimize the visualization of specific tissues in the images. The term \"CT window\" can encompass the concept of a \"bone window,\" which is a specific window setting used to view bone structures more clearly in CT images. \n",
            "\n",
            "While the model's response did not explicitly say \"bone,\" the mention of \"CT window\" gives a relevant clue to the process applied to the images. The model captured part of the concept related to the adjustment or algorithm involved in processing CT scans, but it was not specific enough.\n",
            "\n",
            "Helpfulness: Moderate - Provides partial information related to CT imaging.\n",
            "Relevance: Moderate - The term \"CT window\" is related but not specific.\n",
            "Clarity: Moderate - The answer lacks specificity but introduces a relevant concept.\n",
            "\n",
            "\"Rating: 5/10\"\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r47it [02:26,  3.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is shown in the image?\n",
            "Groud Truth is:  Biocollagen surface at 60  magnification.\n",
            "Prediction is:  Membranes 2ement astfilm layer a days magnification.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is quite unclear and does not provide relevant information that accurately describes what is shown in the image. The response seems to be a garbled mix of words and characters, which detracts significantly from clarity and usefulness. The answer mentions \"Membranes\" at a specific magnification, but it lacks coherence and fails to specify \"Biocollagen\" or correctly describe the subject matter, making it difficult to ascertain its relevance to the question.\n",
            "\n",
            "Since it mentions \"magnification,\" which is relevant to the question, and \"membranes\" might be somewhat related to medical imagery, it does contain at least one key piece of information. However, the majority of the response is unintelligible and off-target.\n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r48it [02:30,  3.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the yellow arrow pointing in the picture? \n",
            "Groud Truth is:  Chitosan microparticles\n",
            "Prediction is:  the fibers surface\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"the fibers surface,\" does not accurately address the question regarding the yellow arrow pointing to chitosan microparticles. The response seems to be describing a texture or component that might be present in a microscopic or material context but is not directly relevant or correct in identifying chitosan microparticles. It lacks the specificity required to be deemed useful or relevant. Thus, the answer does not provide any of the necessary key information expected for the question.\n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r49it [02:32,  3.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the unusual feature observed in the image? \n",
            "Groud Truth is:  An extra cellular layer\n",
            "Prediction is:  Abnormal intercellular cell material of\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Abnormal intercellular cell material of,\" is incomplete and lacks clarity. While it suggests an abnormality between cells, it does not specify the presence of an \"extra cellular layer,\" which is the key unusual feature in the image. The response is not very helpful or relevant without completing the thought or providing more relevant context. The model's answer only partially overlaps with the correct answer and doesn't provide sufficient information to be considered close to the correct response.\n",
            "\n",
            "Rating: 4/10\n",
            "Numeric Score: 0.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r50it [02:34,  2.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What are the stained structures depicted as purple and pink, respectively? \n",
            "Groud Truth is:  Cell nuclei and extracellular matrix\n",
            "Prediction is:  Nuclenuclei and extracellular matrix;\n",
            "GPT-4 Evaluation:\n",
            " The model's answer contains the correct essential information by identifying the stained structures as \"nuclei and extracellular matrix,\" matching the essence of the correct answer. The slight repetition of \"nucle\" and the additional semicolon do not significantly detract from the clarity or relevance of the response. This minor error should not distract from the fact that the primary information is accurate and aligned with the question's requirements.\n",
            "\n",
            "Rating: 9/10\n",
            "Numeric Score: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r51it [02:38,  3.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What color does the ultrasound beam appear as in the image? \n",
            "Groud Truth is:  Yellow\n",
            "Prediction is:  The circle\n",
            "GPT-4 Evaluation:\n",
            " The model's answer lacks helpfulness, relevance, and clarity. While the question specifically asks about the color of the ultrasound beam, the model responds with \"The circle,\" which does not address the question about color. There is no key information given related to the color of the ultrasound beam, which should be \"Yellow.\" For the response to be considered informative or helpful, it would need to mention \"Yellow\" or discuss colors in the image in relation to the ultrasound beam. \n",
            "\n",
            "Overall, the response does not provide any of the correct information and fails to address the core aspect of the question.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r52it [02:41,  2.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the inlay (F) showing? \n",
            "Groud Truth is:  Lateral deformation\n",
            "Prediction is:  Lateral to of\n",
            "GPT-4 Evaluation:\n",
            " The model's answer \"Lateral to of\" is not clear, relevant, or helpful in addressing the medical question. It does not convey a coherent or meaningful response to the question about the inlay (F) showing \"lateral deformation.\" The answer lacks any key information related to the query, and the combination of words and symbols does not form a logical statement that could be interpreted positively.\n",
            "\n",
            "Moreover, there are no elements of the model's answer that align with the expected correct answer. Therefore, it fails to meet the requirements in terms of clarity and relevance.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r53it [02:44,  3.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is marked by the brackets in the image? \n",
            "Groud Truth is:  centrosomes\n",
            "Prediction is:  The omes and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"The omes and,\" is not clear or relevant to the question about identifying centrosomes in the image. It does not provide the correct term or any key information that would indicate an understanding of the question or the image content. Additionally, it appears to be an incomplete phrase that does not make sense in the context of the given question. There is no information that can be deemed useful or close to the real answer. Therefore, the model's response lacks helpfulness, relevance, and clarity.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r54it [02:53,  4.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which part of the heart is affected in an RCM patient? \n",
            "Groud Truth is:  Atria\n",
            "Prediction is:  Right trium icle and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Right trium icle and,\" appears to be an incomplete and incorrect attempt to identify the heart part affected in Restrictive Cardiomyopathy (RCM). The correct answer should identify the atria as the primary part of the heart affected. \n",
            "\n",
            "The model's response lacks clarity and does not accurately identify the atria. The term \"Right trium icle\" seems to be a typographical error, possibly intended to refer to the right atrium, which still would not fully address the question because RCM typically affects both atria. Additionally, the inclusion of \"icle and\" seems to be a typing error and does not provide any relevant information. \n",
            "\n",
            "Overall, the response is not helpful or relevant, as it fails to accurately answer the question. It does not provide any key information that is correct or helpful to the reader about RCM. \n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r55it [02:56,  4.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the source of the photo? \n",
            "Groud Truth is:  Copyrighted\n",
            "Prediction is:  CT ies ightSide\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"CT ies ightSide,\" does not provide any clear, relevant, or helpful information regarding the source of the photo, especially in comparison to the correct answer, \"Copyrighted.\" The model's response seems to be a sequence of random characters or words, failing to convey any meaningful connection to the question asked. There is no key information present in the answer that could be considered for partial credit. \n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r56it [03:00,  4.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is shown in the image? \n",
            "Groud Truth is:  Processed data with lipid droplets\n",
            "Prediction is:  Lipid ed image using FF droplets and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Lipid ed image using FF droplets and,\" appears to be fragmented and lacks coherence. While it does include the mention of \"lipid,\" which is a key term from the correct answer, the rest of the response is incomplete and does not clearly convey the intended meaning of \"processed data with lipid droplets.\" The inclusion of \"FF droplets and\" seems to be an error or irrelevant addition that detracts from the clarity and helpfulness of the response.\n",
            "\n",
            "In summary, the model's answer does touch upon an essential term, \"lipid,\" but fails to construct a complete and understandable response. Therefore, it partially aligns with the correct answer, but the lack of clarity and coherence substantially impacts its relevance and overall helpfulness.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r57it [03:03,  3.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is shown in the scatter plots?\n",
            "Groud Truth is:  M2-like polarization\n",
            "Prediction is:  A projection shaped growth in\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"A projection shaped growth in,\" is neither relevant nor clear in addressing the question \"What is shown in the scatter plots?\" related to \"M2-like polarization.\" It does not provide any key information or concepts linked to the correct topic. The response lacks relevance to M2-like polarization or any indication of an understanding of what is represented in any scatter plots concerning this concept. The answer is incomplete and does not offer valuable insight or a close approximation to the correct answer.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r58it [03:08,  4.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is marked in red in the image? \n",
            "Groud Truth is:  GFAP positive glia\n",
            "Prediction is:  Astro@-@ astrocytes cells\n",
            "GPT-4 Evaluation:\n",
            " The model's answer identifies the cells as \"Astro@-@ astrocytes cells,\" which correctly points toward astrocytes, commonly associated with GFAP (Glial Fibrillary Acidic Protein) positivity. The answer includes extraneous symbols \"@-@\", but the core information is present and relevant to the question. \n",
            "\n",
            "The model's response lacks the clarity expected for professional medical communication due to the inclusion of special characters, but it is still fairly close to the correct answer with the mention of astrocytes, which are indeed GFAP-positive glial cells. The extraneous characters do not hinder understanding significantly.\n",
            "\n",
            "The response is relevant and contains crucial information, making it reasonably helpful to someone with some understanding of the subject.\n",
            "\n",
            "Rating: 7/10\n",
            "Numeric Score: 0.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r59it [03:11,  3.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of image is displayed? \n",
            "Groud Truth is:  Postoperative sagittal MRI scan\n",
            "Prediction is:  Lateral lateral MRI..\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Lateral lateral MRI,\" is not accurate or clear in addressing the medical question about the type of image displayed. The correct answer is a postoperative sagittal MRI scan. The response fails to provide key information and is also redundant by repeating the word \"lateral.\" While it mentions \"MRI,\" which is a relevant term to the context, it does not accurately describe the type of image. Given that it contains a relevant term but does not adequately convey the correct or clear information, the response will receive a partial score.\n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r60it [03:13,  3.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which imaging techniques were used to visualize the hypothalamic mass? \n",
            "Groud Truth is:  PET and CT\n",
            "Prediction is:  FDG and CT,\n",
            "GPT-4 Evaluation:\n",
            " The model's answer provides useful information by correctly identifying CT as one of the imaging techniques used. However, instead of \"PET,\" it mentions \"FDG\", which is related but not exactly accurate. FDG refers to a radiotracer used in PET scans, so it is indirectly relevant but does not precisely answer the question since the question asks for the technique rather than the tracer. The response could be clearer by directly stating \"PET\" instead of \"FDG.\" Overall, the models answer is somewhat close to the correct answer but lacks clarity by not explicitly mentioning \"PET.\"\n",
            "\n",
            "Rating: 7/10\n",
            "Numeric Score: 0.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r61it [03:16,  3.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What imaging technique was used to obtain the views shown in the caption? \n",
            "Groud Truth is:  Magnetic resonance imaging\n",
            "Prediction is:  Magnetic resonance imaging (\n",
            "GPT-4 Evaluation:\n",
            " The model's answer begins correctly by identifying \"magnetic resonance imaging\" as the imaging technique, which matches the correct answer provided. However, the answer is incomplete due to an unfinished sentence that includes an open parenthesis. Despite this, the key information, which is the type of imaging technique, is present and accurately stated. \n",
            "\n",
            "Given that the core information was provided, I'd consider this a partially helpful, relevant, and clear response. The incomplete part of the sentence detracts slightly from the clarity, but as it does not introduce major confusion or errors regarding the key information, it's reasonable to provide a positive score.\n",
            "\n",
            "Rating: 7/10\n",
            "Numeric Score: 0.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r62it [03:18,  2.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of MRI was used pre-operatively to evaluate the brain? \n",
            "Groud Truth is:  T2-weighted MRI\n",
            "Prediction is:  T2-weighted MRI scan\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"T2-weighted MRI scan,\" is succinct and closely aligns with the correct answer, \"T2-weighted MRI.\" The inclusion of the word \"scan\" is extraneous but does not detract from the overall correctness and relevance of the response. The key information, which is the type of MRI used, is accurately conveyed. The response is clear and relevant to the question posed, maintaining its effectiveness and helpfulness. \n",
            "\n",
            "Rating: 9/10\n",
            "Numeric Score: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r63it [03:21,  2.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What additional feature is seen with the mass lesion in the chest CT image? \n",
            "Groud Truth is:  Pleural tags\n",
            "Prediction is:  A nodule in\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"A nodule in,\" is incomplete and does not provide any relevant or helpful information regarding the additional feature seen with the mass lesion in the chest CT image. The expected key information, \"Pleural tags,\" is entirely absent from the response. There is no clarity in the model's response as it doesn't even complete the thought or provide any context. Unfortunately, this attempt does not meet the criteria for a minimum score, as it lacks any relevant information related to the question. \n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r64it [03:28,  4.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What was the location of the cervical dislocation seen in the image? \n",
            "Groud Truth is:  C5 / 6 level\n",
            "Prediction is:  C5-6 cervical cervical\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"C5-6 cervical cervical,\" effectively identifies the level of the cervical dislocation as C5-6, which is consistent with the correct answer, \"C5 / 6 level.\" The repetition of the word \"cervical\" at the end of the response is unnecessary and may slightly detract from the clarity. Nonetheless, the key information regarding the location at the C5-6 level is correctly identified.\n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r65it [03:30,  3.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the subject matter of the electron micrographs? \n",
            "Groud Truth is:  leaf sections\n",
            "Prediction is:  Gercross after\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Gercross after,\" does not provide any helpful, relevant, or clear information related to the subject matter of the electron micrographs. The correct answer, \"leaf sections,\" is entirely different from what the model offered. The response lacks clarity and doesn't include any key information pertinent to the question. The model's answer is not close to the real answer in any way.\n",
            "\n",
            "Therefore, the model's response is not helpful, relevant, or clear and does not meet any of the criteria required for an appropriate answer to the medical question.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r66it [03:33,  3.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the imaging finding in Case 1? \n",
            "Groud Truth is:  Atelectasis\n",
            "Prediction is:  consolidation electasis of\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"consolidation electasis of,\" is somewhat confusing but contains a partial reference to the correct finding of atelectasis. The presence of \"electasis\" suggests an attempt to respond correctly, despite the misspelling. However, the inclusion of \"consolidation\" is potentially misleading, as consolidation typically refers to a different condition on imaging.\n",
            "\n",
            "The answer could be clearer and more precise by directly stating \"atelectasis\" without leading into other terms that are incorrect or not relevant to the specific question. Despite its lack of clarity, the response is at least marginally related to the question due to the mention of \"electasis.\"\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r67it [03:35,  2.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What causes the hyperintensity of the image? \n",
            "Groud Truth is:  Fungal infection\n",
            "Prediction is:  Fungal infection in\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Fungal infection in,\" is incomplete and does not clearly convey the cause of hyperintensity in the image. Although it correctly identifies \"Fungal infection\" as the cause, the answer abruptly ends with \"in,\" making it unclear and incomplete. The lack of clarity and completion reduces its helpfulness and relevance to the question. While the key information is partially present, the response fails to deliver it in a clear and concise manner.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r68it [03:38,  2.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What imaging finding was found in the sagittal plane view?\n",
            "Groud Truth is:  Ground-glass opacities\n",
            "Prediction is:  Sround-glass opacity and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer contains a typographical error, \"Sround\" instead of \"Ground,\" but it still clearly points to the correct imaging finding, which is \"ground-glass opacity.\" Although there's an error, the answer effectively conveys the key information needed: the presence of the ground-glass opacities, aligning well with the correct answer provided. However, the incomplete phrase \"and\" at the end of the response implies there might be additional information missing or an unfinished thought.\n",
            "\n",
            "Overall, the answer is relevant and includes the key finding despite some minor clarity issues due to the typo and the unfinished nature of the response. It provides the main relevant information that aligns with the correct answer.\n",
            "\n",
            "Rating: 7/10\n",
            "Numeric Score: 0.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r69it [03:40,  2.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of medical imaging was used to measure the reduction in lesion density? \n",
            "Groud Truth is:  CT scan\n",
            "Prediction is:  CT scan.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is both relevant and clear, providing the correct type of medical imaging, which is \"CT scan.\" The response is concise and directly addresses the question without unnecessary information. Since it correctly identifies the key piece of information, it meets the requirements for a full score.\n",
            "\n",
            "Rating: 10/10\n",
            "Numeric Score: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r70it [03:42,  2.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What nerve is partially encased by the tumor? \n",
            "Groud Truth is:  Sciatic nerve\n",
            "Prediction is:  Tumor atic nerve and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Tumor atic nerve and,\" unfortunately does not provide the correct answer, \"Sciatic nerve.\" The response lacks accuracy, key information, and coherence, with the phrase \"Tumor atic nerve and\" being nonsensical and lacking both medical relevance and clarity. There is no indication of a correct or even close reference to the sciatic nerve, which is the specific nerve in question. Therefore, the response does not meet the criteria for helpfulness or relevance, and does not earn points for key information.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r71it [03:45,  2.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What do the green arrows represent? \n",
            "Groud Truth is:  Inflammatory cell infiltration\n",
            "Prediction is:  Damcells infiltration of\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Damcells infiltration of,\" does not provide any clear or relevant information to the question. It appears to be incomplete or possibly a typographical error. There is a lack of clarity, as the term \"Damcells\" does not have a known meaning in this context, which suggests it might be a misspelling or misunderstanding of \"inflammatory cell infiltration.\" Furthermore, the answer is not helpful as it doesn't accurately address the query regarding what green arrows represent.\n",
            "\n",
            "No key information is conveyed, and the response diverges significantly from the correct answer. There is no connection between \"Damcells\" and inflammatory cell infiltration, making it neither relevant nor useful. For these reasons, the response would not be considered close to the correct answer.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r72it [03:48,  2.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What type of radiograph is shown in the image? \n",
            "Groud Truth is:  Lateral radiograph\n",
            "Prediction is:  Lateral radiograph.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Lateral radiograph,\" directly corresponds with the correct answer provided to the question. The response is clear, specific, and relevant, as it correctly identifies the type of radiograph depicted. While the answer is concise without additional context or explanation, it fulfills the primary requirement of accurately identifying the radiograph type. The addition of extra symbols or characters might not be necessary, but it does not detract from the correctness of the answer. Overall, the model's straightforward and accurate response deserves a high score.\n",
            "\n",
            "Rating: 10/10\n",
            "Numeric Score: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r73it [03:50,  2.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What imaging modality does the image marked as 1 represent? \n",
            "Groud Truth is:  Fluorocholine PET\n",
            "Prediction is:  PET deoxyglucose PET /\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"PET deoxyglucose PET /\", does mention PET, which is a key imaging modality similar to the correct answer, \"Fluorocholine PET\". However, it incorrectly specifies \"deoxyglucose PET\" (typically FDG PET) rather than \"Fluorocholine PET\", and includes an unnecessary slash at the end. The answer is not entirely accurate, but it partially relates to the correct category of imaging modality, PET. \n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r74it [03:52,  2.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the imaging technique used to generate image (b) in the caption?\n",
            "Groud Truth is:  T1-weighted\n",
            "Prediction is:  T1-weighted sagittal\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"T1-weighted sagittal,\" provides the key information necessary to correctly identify the imaging technique. It includes \"T1-weighted,\" which aligns with the correct answer. The additional specification of \"sagittal\" conveys more detail about the orientation of the scan, which might be relevant depending on the context, although it was not required by the original question. The response is helpful, relevant, and clear, capturing the necessary aspect of the question while offering a little more detail. \n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r75it [03:56,  2.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What did the arrows on the CT images indicate? \n",
            "Groud Truth is:  GGO caused by COVID-19\n",
            "Prediction is:  Pneumonia round, by LR@-@ 19 infection\n",
            "GPT-4 Evaluation:\n",
            " The model's answer provides some relevant information indicating the presence of pneumonia, which is associated with lung infections and can be caused by COVID-19. However, it refers specifically to \"Pneumonia round, by LR@-@ 19 infection,\" which introduces ambiguity due to the non-standard terminology and symbols. The correct answer is GGO (ground-glass opacity), a specific finding often observed in COVID-19 pneumonia. The model's response is not clear regarding the specific feature (GGO) and its association with COVID-19, although it partially aligns by mentioning pneumonia due to an infection. Despite the confusion, the model captures the primary concept that the CT image shows pneumonia due to an infection.\n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r76it [03:58,  2.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What imaging technique was used to produce the image? \n",
            "Groud Truth is:  Positron Emission Tomography (PET)\n",
            "Prediction is:  PET Emission Tomography (PET).\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"PET Emission Tomography (PET),\" contains a minor error in the repetition of \"PET\" as an abbreviation and in the terminology. However, it does convey the correct imaging technique by identifying \"PET,\" which stands for Positron Emission Tomography. The key information, identifying PET as the imaging technique, is present, despite the slight error in phrasing. The answer is quite close to the correct answer and provides relevant information, achieving its main goal. \n",
            "\n",
            "**Rating: 8/10**\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r77it [04:04,  3.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is shown in the X-ray image? \n",
            "Groud Truth is:  Lytic lesion in the left femur\n",
            "Prediction is:  Osteytic lesion with the left femur head\n",
            "GPT-4 Evaluation:\n",
            " The models answer identifies the condition as an osteytic lesion, but this term is not widely recognized in medical terminology and likely intended to be \"osteolytic lesion. Despite this, it captures the essence of a lytic or destructive process affecting the bone, which is a key characteristic of a lytic lesion. The attempt to specify the location as affecting the left femur head shows awareness of the relevant skeletal region, though it misses the precise detail of being in the femur rather than specifically its head. The response demonstrates partial relevance and a basic understanding necessary for identifying a possible bone lesion, albeit with a terminology error. \n",
            "\n",
            "Rating: 5/10\n",
            "Numeric Score: 0.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r78it [04:06,  2.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  Which modality was used to create the image shown in the caption? \n",
            "Groud Truth is:  MRI scan\n",
            "Prediction is:  MRI scan.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is concise and directly addresses the question by confirming the use of an \"MRI scan\" to create the image. It matches the correct answer provided, demonstrating relevance and clarity. While brief, the response successfully conveys the necessary information without confusion or ambiguity. Since the answer is accurate and aligns with the expected response, it satisfies both helpfulness and relevance criteria effectively.\n",
            "\n",
            "Rating: 10/10\n",
            "Numeric Score: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r79it [04:11,  3.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which part of the mouse's body was analysed in this study? \n",
            "Groud Truth is:  Heart\n",
            "Prediction is:  the cells\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"the cells,\" is not specific enough to be considered correct or relevant to the original question about which part of the mouse's body was analyzed. The correct answer, \"Heart,\" identifies a specific organ, whereas \"the cells\" can refer to any part of the body and does not convey the necessary information about the particular body part analyzed. The response lacks relevance and clarity because it does not provide the crucial information required to answer the question accurately.\n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r80it [04:14,  3.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What type of microscopy images were captured? \n",
            "Groud Truth is:  Multispectral images\n",
            "Prediction is:  Fluorescence spectral imaging.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Fluorescence spectral imaging,\" is relevant and closely related to the correct answer, \"Multispectral images.\" Both types of imaging techniques are advanced methods used in microscopy to capture a range of spectral data. While the model's answer does not exactly match the correct answer, it still provides a pertinent type of spectral imaging. The answer is clear and concise, even though it isn't exactly the correct term. Given that it captures a related concept within the context of spectral imaging, the response is helpful.\n",
            "\n",
            "Rating: 7/10\n",
            "Numeric Score: 0.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r81it [04:20,  4.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is shown in the panel? \n",
            "Groud Truth is:  A close-up view of the leaf\n",
            "Prediction is:  A leaf-up view of a leaf surface\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"A leaf-up view of a leaf surface,\" is somewhat unclear due to the phrase \"leaf-up,\" which might be a typographical error or an unintentional play on words. However, it captures the essential idea that the panel shows a view of the leaf surface. \n",
            "\n",
            "For helpfulness, the model's response does attempt to convey what is depicted, though the error may confuse readers.\n",
            "\n",
            "In terms of relevance, the response is pertinent to the question and maintains focus on the subject, aligning with the asked context.\n",
            "\n",
            "For clarity, while the main point is delivered, the unusual wording reduces the clarity of the message slightly.\n",
            "\n",
            "Overall, despite the awkward phrasing, the response contains the critical information needed to answer the question. Thus, a fair score should reflect the core point being successfully communicated despite minor linguistic errors.\n",
            "\n",
            "Rating: 7/10\n",
            "Numeric Score: 0.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r82it [04:23,  3.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What does the bottom panel show? \n",
            "Groud Truth is:  The difference in the L2-norm spectrum due to dStripe\n",
            "Prediction is:  The image between signal signal histogram L5 weights between to the MR atum es removal\n",
            "GPT-4 Evaluation:\n",
            " The model's answer lacks clarity and coherence, making it difficult to determine its helpfulness and relevance. The response is filled with seemingly random words and phrases, such as \"signal signal histogram\" and \"L5 weights,\" which do not appear to be related to the question posed or the correct answer. Moreover, there are no clear references to \"difference,\" \"L2-norm,\" \"spectrum,\" or \"dStripe\"the key components of the correct answermaking it evident that the answer misses all the important information needed to accurately address the question.\n",
            "\n",
            "The lack of any recognizable or meaningful content related to the original query means that the models response is not useful for someone trying to understand what the bottom panel shows in this context. Therefore, despite potential attempts at forming a response, the answer falls short of providing any key information.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r83it [04:26,  3.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What does the long thin arrow demonstrate? \n",
            "Groud Truth is:  Fundus-isthmus length\n",
            "Prediction is:  T2 us color myometrial-(\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"T2 us color myometrial-(\", does not provide a clear or coherent response to the question. The question asks about what a long thin arrow demonstrates, specifically referencing \"Fundus-isthmus length.\" The model's answer contains terms like \"T2,\" \"us,\" and \"myometrial,\" which are relevant to medical imaging and anatomy, suggesting some understanding of medical context. However, the answer lacks clarity and doesn't directly address or explain the concept of \"Fundus-isthmus length.\" The inclusion of additional symbols (\"-(\") further detracts from the clarity and usefulness of the response. It contains relevant terms, but ultimately fails to address the question properly.\n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r84it [04:28,  3.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of image is shown in the figure? \n",
            "Groud Truth is:  3D image\n",
            "Prediction is:  3D image reconstruction\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"3D image reconstruction,\" is closely aligned with the correct answer, \"3D image.\" It shows an understanding of the type of image being referred to and includes a key detail about the nature of the image being a reconstruction. While the word \"reconstruction\" is additional, it is still related to the original term and does not detract from the clarity or relevance of the answer. The answer is both helpful and relevant, providing a clear description that fits well within the context of the question. Given the proximity to the correct answer, the model's response deserves a good score.\n",
            "\n",
            "Rating: 9/10\n",
            "Numeric Score: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r85it [04:30,  2.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What type of procedure was performed for the enlarged hilar lymph node? \n",
            "Groud Truth is:  Endoscopic ultrasound  guided fine  needle aspiration\n",
            "Prediction is:  Endoscopic ultrasound with guided fine needle needle aspiration (\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is very close to the correct answer, \"endoscopic ultrasound  guided fine  needle aspiration.\" It includes both key components: the use of an endoscopic ultrasound and the fine-needle aspiration procedure. While there is a minor repetition with \"needle,\" it captures the essential information needed to understand the procedure performed for the enlarged hilar lymph node. The answer is helpful, relevant, and clear despite the slight issue with wording. \n",
            "\n",
            "Rating: 9/10\n",
            "Numeric Score: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r86it [04:33,  2.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What does the yellow region denote in the image? \n",
            "Groud Truth is:  Reference segmentation\n",
            "Prediction is:  The region in\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"The region in,\" is incomplete and does not provide the necessary explanation or relevant information about what the yellow region denotes, which should be \"Reference segmentation.\" There is no key information provided, and the response lacks clarity and relevance to address the question. While it may be a typographical error or an unfinished sentence, the response does not fulfill the requirement for helpfulness and is missing the core answer. \n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r87it [04:36,  2.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Where is the thromboembolism seen in the image? \n",
            "Groud Truth is:  splenic artery,\n",
            "Prediction is:  Left artery and left\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Left artery and left,\" lacks clarity and specificity. It does not directly address the question nor does it mention the splenic artery, which is the correct location for the thromboembolism. The response is vague and potentially misleading, as it does not provide any accurate or relevant information related to the medical query. Since the answer fails to include the primary key informationidentification of the thromboembolism in the splenic arteryit does not meet the criteria for a helpful or relevant response. \n",
            "\n",
            "Rating: 2/10\n",
            "Numeric Score: 0.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r88it [04:43,  4.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which part of the heart shows severe enlargement?\n",
            "Groud Truth is:  Left atrium\n",
            "Prediction is:  Left ventricle and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Left ventricle and,\" is not fully correct. While it mentions the left ventricle, which can be related to heart enlargement issues, the specific medical question asks about severe enlargement of the left atrium. Therefore, the model's answer does not directly address the asked query of which part shows severe enlargement. The response is incomplete and lacks proper analysis related to the heart part mentioned in the questionnamely, the left atrium. While the mention of the \"left ventricle\" might be relevant in specific contexts of heart enlargement, it doesn't directly address the question regarding the left atrium.\n",
            "\n",
            "Helpfulness: The answer is not helpful as it doesn't accurately answer the question.\n",
            "Relevance: The mention of the \"left ventricle\" is somewhat relevant in a general discussion about heart enlargement, but it is not relevant to the specific query.\n",
            "Clarity: The response ends abruptly with \"and,\" which reduces its clarity.\n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r89it [04:45,  3.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What is the type of medical case being shown in the image? \n",
            "Groud Truth is:  Neurology\n",
            "Prediction is:  Slogand\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Slogand,\" appears to be a misspelling or completely unrelated term rather than a relevant term, specialty, or condition associated with the image related to neurology. It lacks clarity, relevance, and helpfulness, as it does not provide any indication of being associated with the correct field or information needed for the question. Since it does not offer any key information related to the correct answer, it cannot be considered close to accurate.\n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r90it [04:48,  3.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which cranial nerves are involved due to the inflammation?\n",
            "Groud Truth is:  7th and 8th\n",
            "Prediction is:  Left and 8th cranial\n",
            "GPT-4 Evaluation:\n",
            " The model's answer partially aligns with the correct response by identifying the involvement of the \"8th cranial\" nerve, which is accurate. However, it incorrectly mentions \"Left\" instead of the \"7th cranial\" nerve, which detracts from the answer's accuracy and clarity. The model's answer does include one key piece of information, thus deserving partial credit. The response is somewhat helpful and relevant, though it lacks full precision. \n",
            "\n",
            "Rating: 6/10\n",
            "Numeric Score: 0.60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r91it [04:51,  3.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is depicted in the white boundary box? \n",
            "Groud Truth is:  3D volume of perlecan within an NP chondron.\n",
            "Prediction is:  A rendering rendering a ithan deposition a astrocyte. ron.\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"A rendering rendering a ithan deposition a astrocyte. ron.\" is largely unclear and lacks coherence. It does not provide any relevant information in relation to the correct answer, which is a \"3D volume of perlecan within an NP chondron.\" Additionally, the mention of \"ithan deposition\" and \"astrocyte\" is not relevant to the context provided by the question. The repetition of \"rendering\" and the term \"ron\" at the end further contribute to its lack of clarity.\n",
            "\n",
            "While there may be some terms that seem related to biological topics, they do not convey the necessary key information about the image, nor do they connect well with the context of the NP chondron or perlecan. The response fails to offer pertinent or helpful information about the depiction in the white boundary box.\n",
            "\n",
            "Given these issues, the response falls significantly short of providing a useful or relevant answer.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r92it [04:54,  3.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What do filled flat arrowheads indicate in the image? \n",
            "Groud Truth is:  muscle attachments above claws\n",
            "Prediction is:  The fibers on the aws and\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"The fibers on the aws and,\" appears incomplete and doesn't provide enough details or relevant information to satisfactorily address the question about the filled flat arrowheads indicating muscle attachments above claws. There is no mention of muscle attachments, claws, or any connection to the correct answer. Without any key information provided, it fails to clearly or helpfully answer the question.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r93it [04:56,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What did the scans reveal in the coronal plane? \n",
            "Groud Truth is:  Scattered ground glass opacities\n",
            "Prediction is:  Bilateral tered shad@-@ opacities in\n",
            "GPT-4 Evaluation:\n",
            " The model's response, \"Bilateral tered shad@-@ opacities in,\" is incomplete and lacks clarity. The key information in the correct answer is \"scattered ground glass opacities,\" and the model's answer does not convey this critical information. Furthermore, the presence of special characters and incomplete words makes the response difficult to understand and reduces its helpfulness and relevance to the question. In summary, the model's response fails to include the essential detail of \"ground glass opacities,\" which is the key information needed here.\n",
            "\n",
            "Rating: 3/10\n",
            "Numeric Score: 0.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r94it [04:58,  2.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   Which imaging modality was used to capture the image in the caption? \n",
            "Groud Truth is:  Magnetic Resonance Imaging (MRI)\n",
            "Prediction is:  Magnetic Resonance Imaging (MRI).\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Magnetic Resonance Imaging (MRI),\" is both clear and concise, directly addressing the question by naming the correct imaging modality. The response is relevant and helpful because it matches the expected correct answer provided. It presents the key information without unnecessary details or errors, demonstrating an understanding of the question. The presence of a period at the end doesn't detract from the clarity or accuracy of the answer. \n",
            "\n",
            "Overall, the model has effectively addressed all aspects of the query with the essential information needed. \n",
            "\n",
            "Rating: 10/10\n",
            "Numeric Score: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r95it [04:59,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What area of the colon is affected by pneumatosis intestinalis in this image? \n",
            "Groud Truth is:  Right colon\n",
            "Prediction is:  Right colon wall\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Right colon wall,\" is very close to the correct answer, \"Right colon.\" It effectively identifies the right area of the colon but adds the term \"wall,\" which is not necessary for the answer. However, this additional specification does not detract from the primary information and doesn't indicate a misunderstanding. The response is clear and remains relevant to the question, clearly identifying the correct location of pneumatosis intestinalis as the right colon.\n",
            "\n",
            "Rating: 9/10\n",
            "Numeric Score: 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r96it [05:01,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What are the three tracts that make up the optic tract? \n",
            "Groud Truth is:  Anterior inferior optic tract (AIOT), Posterior superior optic tract (PSOT), Lobula optic tract (LOT)\n",
            "Prediction is:  Anterior and and nerve, AIOT) and anterior superior optic nerve (PSOT), Anterior agenes, ((LOT),\n",
            "GPT-4 Evaluation:\n",
            " The model's answer is largely inaccurate and confusing. It includes several nonsensical and disconnected terms such as \"Anterior and and nerve\" and \"Anterior agenes,\" which are not recognized components of the optic tract. Additionally, the model erroneously repeats parts of the correct answer without offering clarity or accuracy.\n",
            "\n",
            "The answer lacks clarity, coherence, and accuracy, failing to identify the correct components of the optic tract. As it doesn't accurately present even one part correctly, it does not meet the threshold for at least half the score. \n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r97it [05:03,  2.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What type of diagnostic imaging is shown in the image? \n",
            "Groud Truth is:  Magnetic Resonance Imaging (MRI)\n",
            "Prediction is:  MRI Resonance Imaging (MRI).\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"MRI Resonance Imaging (MRI),\" is somewhat redundant, as \"MRI\" already stands for \"Magnetic Resonance Imaging.\" Despite this, the model's response correctly identifies the imaging type as MRI, which matches the correct answer. The answer is clear and relevant, and it includes the key information needed. While the repetition of \"Resonance Imaging\" is unnecessary, the essential information is conveyed accurately.\n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r98it [05:06,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:  What is the position of the forearm in the images shown? \n",
            "Groud Truth is:  Flexed\n",
            "Prediction is:  Hand or position\n",
            "GPT-4 Evaluation:\n",
            " The model's answer \"Hand or position\" is not relevant or clear in relation to the question about the position of the forearm. The correct answer is \"Flexed,\" which pertains to the specific positioning of the forearm itself. The model's response does not provide any helpful or related information about the position of the forearm and appears to misunderstand or misinterpret the question entirely. Since the answer doesn't contain any relevant information toward the question, it doesn't meet the criteria for even a partial score.\n",
            "\n",
            "Rating: 0/10\n",
            "Numeric Score: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r99it [05:09,  2.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   How many pulmonary metastases are shown in the CT scan? \n",
            "Groud Truth is:  two\n",
            "Prediction is:  Two masses\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Two masses,\" is concise and relevant to the question. It correctly identifies the presence of two entities in the CT scan, which aligns with the number given in the correct answer. The term \"masses\" is appropriately used in a medical context to describe abnormal growths, including metastases. While the model does not explicitly use the word \"metastases,\" it is sufficiently clear to a medical professional that \"masses\" in this context likely refers to metastatic lesions. Therefore, the model's response is both helpful and relevant, capturing the key information required.\n",
            "\n",
            "Rating: 8/10\n",
            "Numeric Score: 0.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [05:11,  3.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "Question is:   What can be seen in the center of the lesion? \n",
            "Groud Truth is:  Stellate scar\n",
            "Prediction is:  Hyperar lesion lesion\n",
            "GPT-4 Evaluation:\n",
            " The model's answer, \"Hyperar lesion lesion,\" does not provide relevant or clear information in response to the question. The term \"stellate scar\" is specific and crucial to understanding what is typically seen in the center of certain lesions, such as renal oncocytomas or fibromas. The provided answer repeats the word \"lesion\" and introduces \"Hyperar,\" which does not appear to correspond to any known medical terminology related to the context. This response lacks both helpfulness and relevance and does not convey the key information required to answer the question correctly.\n",
            "\n",
            "Rating: 1/10\n",
            "Numeric Score: 0.10\n",
            "Average score (0-1 scale): 0.4190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(['The model\\'s answer, \"Cpcyst of,\" does not provide a clear or relevant response to the medical question. The intended answer, \"Colloid cyst,\" is not recognizable in the model\\'s response. The model\\'s answer contains jumbled characters and lacks any key information related to the correct answer. Consequently, it fails to meet any of the criteria for helpfulness, relevance, or clarity in this context.\\n\\nRating: 0/10',\n",
              "  'The model\\'s answer, \"Ultrasound ultrasound image,\" is neither clear nor helpful in identifying the type of ultrasound image specified in the question. It simply repeats the word \"ultrasound\" without providing any relevant information. The correct answer involved specifying that it is a 3D ultrasound image, which the model failed to do. There is no key information provided in the response, and it does not offer any clarity or relevance to the question asked.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"CT tumor no evidence invasion,\" accurately conveys the key information that there is no evidence of invasion, which pertains to the assessment of the tumor\\'s condition. While the answer lacks clarity and completeness due to its brevity and lack of specificity (it does not explicitly mention whether the tumor is benign), it captures a critical aspect of the original answer concerning the absence of serosal invasion. The response would benefit from a more complete sentence and the inclusion of the term \"benign\" to enhance clarity and relevance.\\n\\nRating: 6/10',\n",
              "  'The model\\'s answer, \"Nile izn,\" does not provide a relevant or correct response to the question about which staining method is used in the bottom row of images. The correct answer is \"Male staining,\" and the provided answer does not include any useful or key information related to this. While it may have been an attempt at generating relevant content, the response lacks clarity and does not closely resemble the correct answer.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"Uterine us tissue,\" is quite close to the correct answer, \"Uterus.\" However, it includes an unnecessary and confusing term, \"us,\" which could be a typographical error intending to say \"uterus tissue\" or otherwise unintended. Despite this, it still communicates the primary subject fairly well by including the key term \"uterine,\" which relates to the uterus. The additional characters and words slightly reduce the clarity but the overall meaning is generally preserved. Given that the model\\'s response depicts the correct anatomical area related to the uterus, it shows a high level of relevance. It avoids overly detailed or irrelevant information, staying quite close to a correct response.\\n\\nRating: 8/10',\n",
              "  'The models answer, \"Normal flow maps,\" lacks clarity and relevance to the original question. It does not directly address the main parameter being measured in panel F, which is \"blood flow.\" The term \"normal flow maps\" implies a type of map but doesn\\'t specify what is being measured, nor does it directly relate to \"blood flow.\" The response is not sufficiently clear or helpful in this context. Because it does not include the key information about what is actually being measured, the model\\'s response is not particularly informative. \\n\\nRating: 3/10',\n",
              "  'The model\\'s answer, \"Mitral treoventricular valve defect and,\" is not clear or complete. Firstly, it appears to contain a typographical error, \"treoventricular,\" which is likely intended to mean \"atrioventricular.\" However, the answer still does not accurately describe the condition shown in the image, which is an atrioventricular septal defect (AVSD). This defect includes issues with both the atrial septum and ventricular septum as well as abnormalities in the atrioventricular valves. \\n\\nThe model\\'s answer partially touches upon the involvement of a valve, which is relevant to AVSD, but it fails to clearly communicate the condition. The incomplete sentence and the typographical error significantly reduce the clarity and helpfulness of the response. While it does attempt to address the valve involvement, it lacks precision and relevance to the correct medical condition.\\n\\nRating: 3/10',\n",
              "  'The model\\'s answer, \"X cope,\" is unclear and does not provide the correct or relevant information related to the technique used for macroscopic observation of nerve roots postoperatively. It seems to be an incomplete or incorrect word and does not effectively communicate the intended response. The correct technique is an \"endoscope,\" which is not represented in the model\\'s answer. Therefore, the response lacks helpfulness, relevance, and clarity. \\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"Hematoxylin and eosin staining and\", is very close to the correct answer of \"Hematoxylin eosin staining.\" The inclusion of the word \"and\" at the end is extraneous but does not detract significantly from the relevance or helpfulness of the information provided. The key information offered, which is the type of staining used, is accurate and clear. Overall, the answer is relevant and sufficiently meets the question\\'s requirement, despite the unnecessary ending.\\n\\nRating: 9/10',\n",
              "  'The models answer, \"Botmammbody in,\" does not provide a clear or relevant response to the question about a marker clip seen on a mammogram. There is no coherent or medically relevant information presented, and it lacks any helpful or correct detail about what a marker clip is in the context of a mammogram. The inclusion of random characters and words does not contribute any valuable information, thus failing to answer the question adequately.\\n\\nRating: 0/10',\n",
              "  'The model\\'s answer, \"Type fracture in,\" lacks clarity, relevance, and helpfulness. It does not provide any meaningful or correct information related to the question about the type of fracture found on the pre-operative CT scan, which is a stress fracture. The response does not offer any useful content and does not come close to the correct answer. \\n\\nThe model\\'s response does not include any correct or partial key information. Consequently, the answer does not meet the expectations for a helpful response in this context.\\n\\nRating: 0/10',\n",
              "  'The model\\'s answer, \"Confocal equatorial level,\" does not precisely match the correct answer, \"The nuclear plane.\" The term \"confocal\" refers to a technique used in certain types of microscopy, and \"equatorial level\" could suggest a central or balanced focus, but these terms collectively do not substitute for \"nuclear plane.\" While the provided answer does contain elements that could be relevant in a broader microscopy or histological context, it lacks clarity and direct relevance to the specific question asked. Therefore, it offers limited helpfulness. However, since it is somewhat close due to its scientific terminology, it deserves some credit for attempting an educated guess.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer attempts to provide the types of mammogram images used in breast cancer screening, but it is unclear and contains typographical errors. While it mentions \"mediolateral,\" which is part of the correct term \"mediolateral oblique,\" it fails to accurately convey the full names of the standard views, \"bilateral craniocaudal\" and \"mediolateral oblique.\" The use of incorrect or misspelled terms such as \"mambreast\" and \"audal\" detracts from the clarity and professionalism of the response. Therefore, while the answer contains one key piece of information, it is not sufficiently accurate or clear to be considered helpful or relevant.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"Superior retina superior temporal,\" partially addresses the question by mentioning the \"superior retina.\" However, it omits \"peripheral retina,\" which is also part of the correct answer. The inclusion of \"superior temporal\" introduces an additional, less relevant detail that may confuse the response. While it captures one of the required areas, the lack of mention of the peripheral retina results in incomplete information. It is important for the answer to clearly specify both required areas to be fully helpful and relevant.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"T1 scan MRI scan,\" provides partial information regarding the type of scan used in the image fusion. It correctly identifies the use of an MRI scan, specifying a T1-weighted MRI, which is relevant information. However, it misses mentioning the use of a CT scan, which is also part of the correct answer. \\n\\nThe response is somewhat helpful and relevant, as it identifies one of the imaging modalities involved but lacks completeness. In terms of clarity, the phrase \"T1 scan MRI scan\" could be slightly confusing due to repetition and lack of context.\\n\\nDespite these issues, the answer does include at least one key piece of information, therefore it deserves partial credit but does not fully answer the question posed.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer is unclear and contains errors. It misidentifies the directions and provides a nonsensical list (\"Vand lateral, and, and\") instead of the correct anatomical terms (\"dorsal, ventral, medial\"). There is no indication of understanding or relevance in the response, as it does not match any part of the correct answer. \\n\\nDespite needing improvements, since the model attempted to mention \"lateral\" which is an anatomical direction (albeit not from the correct list), some partial credit might be given for proximity to relevant terms.  \\n\\nRating: 2/10',\n",
              "  'The model\\'s answer, \"The sensifruit-,\" does not provide any relevant or clear information related to the question about what the red star indicates in the image. There is no connection between \"sensifruit-\" and a \"mature air pore,\" which is the correct answer. The response lacks key information and does not contribute any understanding to the query. Therefore, it falls short in terms of helpfulness and relevance. \\n\\nRating: 1/10',\n",
              "  'The model\\'s answer \"C5-\" is incorrect in identifying the lesion location, which was correctly answered as \"C2.\" While the answer is related to spinal segment identification, it doesn\\'t provide the correct location or convey any key information regarding the question asked. The presence of the additional character \"-\" does not add value, clarity, or relevance. Overall, the model\\'s response lacks helpfulness, relevance, and clarity, as it fails to provide the correct answer or any part of it. \\n\\nRating: 3/10',\n",
              "  'The model\\'s answer, \"Normal tina and,\" appears to be an incomplete and incorrect representation of the correct answer, which is \"Retina.\" The response lacks clarity and relevance as it neither identifies the correct part of the eye nor provides a coherent contribution to the question. There is no discernible key information present in the model\\'s response, so it does not meet the criteria for at least half the score, which would require some relevant information to be present. Despite the response being close in terms of phonetic sound at the beginning (\"tina\" resembling \"retina\"), it does not accurately convey the intended meaning or concept required to answer the question.\\n\\nRating: 2/10',\n",
              "  'The model\\'s answer is reasonably helpful and relevant, addressing the key information required to respond to the question. It clearly identifies the left anterior descending artery as involved, which is critical to understanding the context of the chest pain. However, the wording is somewhat awkward (\"Left stenosis in occlusion of the left anterior descending artery artery in\"), and there is a repetition of the word \"artery,\" which impacts clarity. Despite this, the model\\'s response effectively communicates the essential idea, aligning closely with the correct answer. Overall, while there\\'s room for improvement in terms of clarity, the response sufficiently conveys the necessary information.\\n\\nRating: 8/10',\n",
              "  'The model\\'s answer, \"Masson\\'s rome staining tain,\" is close to the correct answer but contains typographical errors. It demonstrates an understanding of the staining method by including the term \"Masson\" and an attempt at \"Trichrome,\" which indicates some recognition of the correct method. However, clarity is compromised due to these errors, which could lead to confusion. It doesn\\'t perfectly match \"Masson Trichrome Stain,\" but acknowledges the key element, which is \"Masson\". Although it lacks precision, it possesses part of the relevant information. \\n\\nRating: 5/10',\n",
              "  'The model\\'s answer does not correctly address the question about what the red and green dots represent in the radiographs. The provided answer mentions \"Medial length of the metatarsal heads I,\" which does not relate to the centers of the metatarsal bone. The response lacks relevance to the original question, as it does not mention the centers of the metatarsal bones or explain what the dots signify meaningfully. \\n\\nWhile the answer includes terms related to metatarsal anatomy, it diverges significantly from the correct interpretation. Therefore, the clarity and helpfulness of the response are limited. A closer approximation to the correct answer is needed to warrant a higher score.\\n\\nRating: 3/10',\n",
              "  'The model\\'s answer, \"CT scan,\" directly matches the correct answer provided for the question. It is concise, relevant, and clear, addressing the specific type of imaging used to assess the acetabular fracture after surgery without unnecessary elaboration. Therefore, it effectively satisfies all the criteria of helpfulness, relevance, and clarity.\\n\\nRating: 10/10',\n",
              "  'The model\\'s answer, \"Hyperioma and\", is not relevant or helpful to the question. The term \"Hyperioma\" is not a recognized medical condition or diagnosis, suggesting a possible misunderstanding or error in the model\\'s response. The answer does not provide any key information that aligns with the correct diagnosis of \"Meningioma.\" Due to the complete lack of relevance and helpfulness in addressing the question, the evaluation of the model\\'s answer can only reflect the absence of any pertinent information or clarity.\\n\\nRating: 0/10',\n",
              "  'The model\\'s answer, \"Thoracic spine 1,\" refers to a specific vertebra within the thoracic spine segment, which is closely related to the given correct answer, \"thoracic vertebrae.\" The model\\'s response is relevant as it indicates a location within the thoracic region of the spine, and it provides a specific vertebra (the first thoracic vertebra, T1). While it is slightly less general than the correct answer, it still contains key information about the general location within the thoracic area, which is pertinent to the question.\\n\\nThe response is helpful in that it identifies the thoracic spinal region, which matches the context of the question. However, the use of \"Thoracic spine 1\" might lead to some confusion if misinterpreted as referring specifically to only one vertebra rather than the general thoracic vertebrae region, but it still points the reader in the correct direction.\\n\\nOverall, the answer is relevant and clear, containing the essential information needed to identify the location of the metastasis, though it could be misinterpreted as overly specific.\\n\\nRating: 8/10',\n",
              "  'The model\\'s response, \"St@-@ acia n starch film ard,\" is not helpful, relevant, or clear in identifying the type of custard in the image. The answer does not contain any key information that corresponds to the correct answer, \"Alkaline acorn starch custard.\" The response seems to be a nonsensical string of characters and words without any meaningful content. It fails to convey any component of the correct answer. Thus, it is not possible to assign a score of at least half in this case as there is no recognizable link to the correct answer.\\n\\nRating: 0/10',\n",
              "  'The model\\'s answer, \"Muscle cells fibers,\" is largely accurate but slightly awkward in phrasing. It likely meant to convey \"muscle cell fibers\" or \"muscle fibers,\" which are indeed related to muscle cells and an appropriate response to the question. The inclusion of the term \"fibers\" suggests an understanding of the structure of muscle cells, which are often referred to as muscle fibers due to their elongated shape.\\n\\nHelpfulness: The answer directly addresses the question and seems to be identifying muscle cell structure correctly, given that muscle fibers are a common way to refer to muscle cells.\\nRelevance: The answer stays on topic and connects well to what was asked.\\nClarity: The phrase could be clearer, primarily due to the redundant pluralization, but the core idea is still conveyed.\\n\\nOverall, while the response could be slightly improved in phrasing for clarity, it communicates the necessary information effectively.\\n\\nRating: 8/10',\n",
              "  'The model\\'s answer \"CT scan\" is incorrect as the correct imaging type for the question is \"MRI.\" The response lacks helpfulness and relevance because it fails to provide the correct type of imaging. Clarity is satisfactory in that the response is concise, but it is misleading since it is inaccurate. There is no key information provided that aligns with the correct answer, therefore it does not score well in terms of helpfulness. \\n\\nRating: 2/10',\n",
              "  'The model\\'s answer is unclear, lacks relevance, and does not address the question adequately. It neither mentions the semilunar valves nor provides any helpful information related to the correct answer. The additional text \"Lymphof lymphoid itunar lymphatic and\" is not related to the formation of semilunar valves, which is the key information required to answer the question correctly. Given these shortcomings, the response does not deserve a high score. \\n\\nRating: 1/10',\n",
              "  'The model\\'s answer is \"macular-related macular degeneration (\". This response is attempting to identify the condition as macular degeneration, which is indeed the correct general category. However, the answer is not fully accurate as the condition specified in the question is \"age-related macular degeneration.\" The model\\'s response also ends with an incomplete phrase, suggesting the possibility of an unfinished thought or typographical error. \\n\\nWhile the model\\'s response is in the right direction by identifying \"macular degeneration,\" it lacks precision and clarity. Yet, it is related to the correct answer, as it identifies the macular aspect of the condition. Therefore, it offers at least a partial recognition of the key information required.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"Proximal femur of,\" includes the key information that the tumors occur in the \"proximal\" part of the femur. While the structure of the response is slightly incomplete due to the dangling \"of,\" it still effectively communicates the primary location being asked about. The answer is relevant and mostly clear in identifying that the tumors occur in the proximal part of the femur. Given that it contains the crucial information needed to answer the question, it meets the requirements for a good understanding of the question. Thus, it deserves a reasonable score.\\n\\nRating: 8/10',\n",
              "  'The model\\'s answer, \"CT CT CT scan,\" unfortunately lacks helpfulness, clarity, and relevance. It doesn\\'t effectively communicate which type of imaging is not shown in the image. Repetition of \"CT\" does not contribute to clarity and may confuse the reader. The model should directly state the specific type of CT scan that is missing or not shown. It is not close to the correct answer, \"Cranial enhanced CT,\" and therefore does not meet the criteria for a good score, as it fails to include any key information.\\n\\nRating: 2/10',\n",
              "  'The model\\'s answer, \"X scan image 3D position,\" lacks clarity and specificity in addressing the question. It does not mention CT scan or the prone position, which are the key components of the correct answer. The model\\'s response appears to be vague and somewhat random, without providing any helpful or relevant information related to the topic of imaging and anatomical positions used for body surface marking.\\n\\nWhile the model\\'s answer does hint at something related to scanning and position with the words \"scan\" and \"3D position,\" it does not effectively convey the correct information or relate directly to the specific query. \\n\\nOverall, the model\\'s response falls short in helpfulness, clarity, and relevance, and fails to provide any of the key information needed to answer the question correctly.\\n\\nRating: 2/10',\n",
              "  'The model\\'s answer, \"MRI scan,\" is accurate and relevant, as it correctly identifies the imaging modality used to visualize the mass in the left buccal region. The addition of the word \"scan\" does not detract from the clarity or helpfulness of the response, as it reinforces that MRI refers to an imaging technique. The answer is clear and directly addresses the question without unnecessary details. Overall, the response is both correct and concise, aligning closely with the correct answer.\\n\\nRating: 10/10',\n",
              "  'The model\\'s answer, \"Brain of a scans segmentation on,\" is attempting to address the question regarding what is being compared in the image. However, the response lacks clarity and the necessary detail to convey that it is about the results of brain tumor segmentation. It includes some relevant terms, such as \"Brain\" and \"segmentation,\" which suggest it is on the topic of medical imaging analysis, but it doesn\\'t effectively convey the complete concept of \"brain tumor segmentation.\" The phrase structure is incoherent, making it difficult to accurately interpret the intended message.\\n\\nThe answer does contain at least one key piece of information pertinent to the desired answer, specifically the term \"segmentation,\" which is integral to understanding the focus of the comparison. However, the lack of coherence and specificity detracts considerably from the overall helpfulness and relevance to the original question.\\n\\nIn light of these observations, while acknowledging the presence of a critical term, the response falls short in terms of clarity and precision.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer \"L4-L5 disc\" captures the key information about the specific vertebrae affected, which are L4-L5. However, the term \"disc\" could imply additional context related to disc issues, which is not explicitly asked in the question that focuses on which vertebrae are affected. Despite this slight deviation, the answer still directly addresses the question by identifying the correct vertebrae. The mention of \"disc\" does not obscure the core information, making the response relevant, relatively clear, and helpful for understanding which vertebrae are involved. \\n\\nRating: 8/10',\n",
              "  'The model\\'s answer \"Stomas and\" does not provide relevant or clear information in response to the question about organ location based on a CT scan. The correct organ in question is the pancreas, and the response given fails to address this or provide any related anatomical reference. The term \"stomas\" is unrelated to the context of organ placement and encapsulated collections in a CT scan, leading to confusion rather than clarity. As such, the response neither provides useful information nor answers the question in a meaningful way. \\n\\nRating: 0/10',\n",
              "  'The model\\'s answer, \"Hemorrhage hyposignal in,\" is incomplete and does not directly align with the correct answer, \"Heterogeneous bright signal.\" The key term \"hyposignal\" is incorrect as it contradicts the \"bright signal\" part of the correct answer. Furthermore, the phrase is incomplete and lacks necessary context to be helpful. The model\\'s response does not capture the main feature described in the correct answer.\\n\\nWhile there might be an attempt to identify a signal characteristic in imaging, the response does not provide the correct or complete information needed to evaluate the finding accurately. The answer lacks relevance and clarity, and therefore does not adequately address the question.\\n\\nRating: 2/10',\n",
              "  'The model\\'s answer, \"Right turmuscle muscle on,\" does not convey clear or relevant information regarding the affected muscle in the context of the CT scan. There appears to be a misunderstanding or miscommunication in the response with invented terms such as \"turmuscle.\" As a result, the answer fails to identify the correct muscle, \"oblique abdominal muscle.\" The response lacks clarity and alignment with the question\\'s requirements.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer attempts to address the question, but it contains errors and lacks clarity. The phrase \"Proximal humerus humerus\" is repetitive and unclear. It incorrectly mentions the \"distal clavicle,\" which is not a part of the arm typically visible in an X-ray focused on the humerus. The mention of \"distal-area\" is also vague and not consistent with the expected parts in the context of an arm X-ray. However, it does mention the \"proximal humerus,\" which is partly correct. \\n\\nTo improve, the response should accurately include the areas: proximal humerus, middle shaft, and supra condylar area/fracture. This would make it more relevant and helpful. Given that the model includes one key part of the correct answer but has several inaccuracies and lacks clarity, it receives partial credit.\\n\\nRating: 4/10',\n",
              "  'The model\\'s answer partially conveys key information relevant to the ultrasound findings but lacks clarity and completeness. The mention of \"heterogeneous hypoechoic nodules\" somewhat aligns with \"multiple hypoechoic masses,\" which is a critical element of the correct answer. However, the response is marred by incomplete and unclear phrasing like \"liver echogenicity size,\" which muddles the intended message. Even though it suggests abnormalities in the liver, it doesn\\'t clearly articulate the observation of increased liver size. Improving the overall coherence and directly addressing both \"increased liver size\" and the nature of the hypoechoic masses would enhance relevance and clarity.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"The blood,\" is completely unrelated to the question about the presence of a thrombus inside the PA (pulmonary artery) branch. It fails to address the key issue of whether there is a thrombus present and lacks any helpful, relevant, or clear information. The answer does not convey any of the correct information that would provide a suitable response to the question.\\n\\nRating: 0/10',\n",
              "  'The model\\'s answer, \"Proyrria fluorescence,\" is quite close to the correct answer, \"Porphyrazine fluorescence channel.\" The model\\'s attempt demonstrates an understanding of the concept but has a minor error in the spelling of \"Porphyrazine,\" written as \"Proyrria.\" Despite this misspelling, the response is relevant to the question and conveys the key information of a fluorescence channel being used, albeit with an incorrect name.\\n\\nThe answer is not entirely clear due to the spelling error, which could lead to some confusion if someone unfamiliar with the terminology attempted to use or understand the model\\'s response. Nonetheless, the model captures the main idea, providing a response close to what is required.\\n\\nOverall, the model\\'s answer is helpful and relevant but lacks clarity due to the misspelling. It includes the key information, which could be recognized with context in a medical setting, albeit imperfectly.\\n\\nRating: 6/10',\n",
              "  'The model\\'s answer, \"Retinal bretinal fluid,\" attempts to address the question but contains a typographical error with the word \"bretinal\" which doesn\\'t contribute to clarity or relevance. However, it does mention \"fluid,\" which is related to the concept of subretinal detachment, where fluid accumulates under the retina. Although the model\\'s response is not clear and contains inaccuracies, it touches on a pertinent aspect of the condition.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"Arthroia oplasty alocalcaneal Arthrowas with,\" does not clearly convey the correct procedure, which is \"Tibiotalocalcaneal arthrodesis surgery.\" The response appears to be jumbled and lacks coherence, containing invented terms and a distorted version of the medical procedure name. There is no indication that the correct surgical procedure was acknowledged or partially captured by the answer. Thus, it fails to meet expectations in terms of relevance, helpfulness, and clarity. Despite the attempt, it does not provide any key information accurately.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer \"CT window\" is partially relevant. In CT imaging, different window settings (e.g., bone window, soft tissue window) are used to optimize the visualization of specific tissues in the images. The term \"CT window\" can encompass the concept of a \"bone window,\" which is a specific window setting used to view bone structures more clearly in CT images. \\n\\nWhile the model\\'s response did not explicitly say \"bone,\" the mention of \"CT window\" gives a relevant clue to the process applied to the images. The model captured part of the concept related to the adjustment or algorithm involved in processing CT scans, but it was not specific enough.\\n\\nHelpfulness: Moderate - Provides partial information related to CT imaging.\\nRelevance: Moderate - The term \"CT window\" is related but not specific.\\nClarity: Moderate - The answer lacks specificity but introduces a relevant concept.\\n\\n\"Rating: 5/10\"',\n",
              "  'The model\\'s answer is quite unclear and does not provide relevant information that accurately describes what is shown in the image. The response seems to be a garbled mix of words and characters, which detracts significantly from clarity and usefulness. The answer mentions \"Membranes\" at a specific magnification, but it lacks coherence and fails to specify \"Biocollagen\" or correctly describe the subject matter, making it difficult to ascertain its relevance to the question.\\n\\nSince it mentions \"magnification,\" which is relevant to the question, and \"membranes\" might be somewhat related to medical imagery, it does contain at least one key piece of information. However, the majority of the response is unintelligible and off-target.\\n\\nRating: 3/10',\n",
              "  'The model\\'s answer, \"the fibers surface,\" does not accurately address the question regarding the yellow arrow pointing to chitosan microparticles. The response seems to be describing a texture or component that might be present in a microscopic or material context but is not directly relevant or correct in identifying chitosan microparticles. It lacks the specificity required to be deemed useful or relevant. Thus, the answer does not provide any of the necessary key information expected for the question.\\n\\nRating: 2/10',\n",
              "  'The model\\'s answer, \"Abnormal intercellular cell material of,\" is incomplete and lacks clarity. While it suggests an abnormality between cells, it does not specify the presence of an \"extra cellular layer,\" which is the key unusual feature in the image. The response is not very helpful or relevant without completing the thought or providing more relevant context. The model\\'s answer only partially overlaps with the correct answer and doesn\\'t provide sufficient information to be considered close to the correct response.\\n\\nRating: 4/10',\n",
              "  'The model\\'s answer contains the correct essential information by identifying the stained structures as \"nuclei and extracellular matrix,\" matching the essence of the correct answer. The slight repetition of \"nucle\" and the additional semicolon do not significantly detract from the clarity or relevance of the response. This minor error should not distract from the fact that the primary information is accurate and aligned with the question\\'s requirements.\\n\\nRating: 9/10',\n",
              "  'The model\\'s answer lacks helpfulness, relevance, and clarity. While the question specifically asks about the color of the ultrasound beam, the model responds with \"The circle,\" which does not address the question about color. There is no key information given related to the color of the ultrasound beam, which should be \"Yellow.\" For the response to be considered informative or helpful, it would need to mention \"Yellow\" or discuss colors in the image in relation to the ultrasound beam. \\n\\nOverall, the response does not provide any of the correct information and fails to address the core aspect of the question.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer \"Lateral to of\" is not clear, relevant, or helpful in addressing the medical question. It does not convey a coherent or meaningful response to the question about the inlay (F) showing \"lateral deformation.\" The answer lacks any key information related to the query, and the combination of words and symbols does not form a logical statement that could be interpreted positively.\\n\\nMoreover, there are no elements of the model\\'s answer that align with the expected correct answer. Therefore, it fails to meet the requirements in terms of clarity and relevance.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"The omes and,\" is not clear or relevant to the question about identifying centrosomes in the image. It does not provide the correct term or any key information that would indicate an understanding of the question or the image content. Additionally, it appears to be an incomplete phrase that does not make sense in the context of the given question. There is no information that can be deemed useful or close to the real answer. Therefore, the model\\'s response lacks helpfulness, relevance, and clarity.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"Right trium icle and,\" appears to be an incomplete and incorrect attempt to identify the heart part affected in Restrictive Cardiomyopathy (RCM). The correct answer should identify the atria as the primary part of the heart affected. \\n\\nThe model\\'s response lacks clarity and does not accurately identify the atria. The term \"Right trium icle\" seems to be a typographical error, possibly intended to refer to the right atrium, which still would not fully address the question because RCM typically affects both atria. Additionally, the inclusion of \"icle and\" seems to be a typing error and does not provide any relevant information. \\n\\nOverall, the response is not helpful or relevant, as it fails to accurately answer the question. It does not provide any key information that is correct or helpful to the reader about RCM. \\n\\nRating: 2/10',\n",
              "  'The model\\'s answer, \"CT ies ightSide,\" does not provide any clear, relevant, or helpful information regarding the source of the photo, especially in comparison to the correct answer, \"Copyrighted.\" The model\\'s response seems to be a sequence of random characters or words, failing to convey any meaningful connection to the question asked. There is no key information present in the answer that could be considered for partial credit. \\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"Lipid ed image using FF droplets and,\" appears to be fragmented and lacks coherence. While it does include the mention of \"lipid,\" which is a key term from the correct answer, the rest of the response is incomplete and does not clearly convey the intended meaning of \"processed data with lipid droplets.\" The inclusion of \"FF droplets and\" seems to be an error or irrelevant addition that detracts from the clarity and helpfulness of the response.\\n\\nIn summary, the model\\'s answer does touch upon an essential term, \"lipid,\" but fails to construct a complete and understandable response. Therefore, it partially aligns with the correct answer, but the lack of clarity and coherence substantially impacts its relevance and overall helpfulness.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"A projection shaped growth in,\" is neither relevant nor clear in addressing the question \"What is shown in the scatter plots?\" related to \"M2-like polarization.\" It does not provide any key information or concepts linked to the correct topic. The response lacks relevance to M2-like polarization or any indication of an understanding of what is represented in any scatter plots concerning this concept. The answer is incomplete and does not offer valuable insight or a close approximation to the correct answer.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer identifies the cells as \"Astro@-@ astrocytes cells,\" which correctly points toward astrocytes, commonly associated with GFAP (Glial Fibrillary Acidic Protein) positivity. The answer includes extraneous symbols \"@-@\", but the core information is present and relevant to the question. \\n\\nThe model\\'s response lacks the clarity expected for professional medical communication due to the inclusion of special characters, but it is still fairly close to the correct answer with the mention of astrocytes, which are indeed GFAP-positive glial cells. The extraneous characters do not hinder understanding significantly.\\n\\nThe response is relevant and contains crucial information, making it reasonably helpful to someone with some understanding of the subject.\\n\\nRating: 7/10',\n",
              "  'The model\\'s answer, \"Lateral lateral MRI,\" is not accurate or clear in addressing the medical question about the type of image displayed. The correct answer is a postoperative sagittal MRI scan. The response fails to provide key information and is also redundant by repeating the word \"lateral.\" While it mentions \"MRI,\" which is a relevant term to the context, it does not accurately describe the type of image. Given that it contains a relevant term but does not adequately convey the correct or clear information, the response will receive a partial score.\\n\\nRating: 3/10',\n",
              "  'The model\\'s answer provides useful information by correctly identifying CT as one of the imaging techniques used. However, instead of \"PET,\" it mentions \"FDG\", which is related but not exactly accurate. FDG refers to a radiotracer used in PET scans, so it is indirectly relevant but does not precisely answer the question since the question asks for the technique rather than the tracer. The response could be clearer by directly stating \"PET\" instead of \"FDG.\" Overall, the models answer is somewhat close to the correct answer but lacks clarity by not explicitly mentioning \"PET.\"\\n\\nRating: 7/10',\n",
              "  'The model\\'s answer begins correctly by identifying \"magnetic resonance imaging\" as the imaging technique, which matches the correct answer provided. However, the answer is incomplete due to an unfinished sentence that includes an open parenthesis. Despite this, the key information, which is the type of imaging technique, is present and accurately stated. \\n\\nGiven that the core information was provided, I\\'d consider this a partially helpful, relevant, and clear response. The incomplete part of the sentence detracts slightly from the clarity, but as it does not introduce major confusion or errors regarding the key information, it\\'s reasonable to provide a positive score.\\n\\nRating: 7/10',\n",
              "  'The model\\'s answer, \"T2-weighted MRI scan,\" is succinct and closely aligns with the correct answer, \"T2-weighted MRI.\" The inclusion of the word \"scan\" is extraneous but does not detract from the overall correctness and relevance of the response. The key information, which is the type of MRI used, is accurately conveyed. The response is clear and relevant to the question posed, maintaining its effectiveness and helpfulness. \\n\\nRating: 9/10',\n",
              "  'The model\\'s answer, \"A nodule in,\" is incomplete and does not provide any relevant or helpful information regarding the additional feature seen with the mass lesion in the chest CT image. The expected key information, \"Pleural tags,\" is entirely absent from the response. There is no clarity in the model\\'s response as it doesn\\'t even complete the thought or provide any context. Unfortunately, this attempt does not meet the criteria for a minimum score, as it lacks any relevant information related to the question. \\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"C5-6 cervical cervical,\" effectively identifies the level of the cervical dislocation as C5-6, which is consistent with the correct answer, \"C5 / 6 level.\" The repetition of the word \"cervical\" at the end of the response is unnecessary and may slightly detract from the clarity. Nonetheless, the key information regarding the location at the C5-6 level is correctly identified.\\n\\nRating: 8/10',\n",
              "  'The model\\'s answer, \"Gercross after,\" does not provide any helpful, relevant, or clear information related to the subject matter of the electron micrographs. The correct answer, \"leaf sections,\" is entirely different from what the model offered. The response lacks clarity and doesn\\'t include any key information pertinent to the question. The model\\'s answer is not close to the real answer in any way.\\n\\nTherefore, the model\\'s response is not helpful, relevant, or clear and does not meet any of the criteria required for an appropriate answer to the medical question.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"consolidation electasis of,\" is somewhat confusing but contains a partial reference to the correct finding of atelectasis. The presence of \"electasis\" suggests an attempt to respond correctly, despite the misspelling. However, the inclusion of \"consolidation\" is potentially misleading, as consolidation typically refers to a different condition on imaging.\\n\\nThe answer could be clearer and more precise by directly stating \"atelectasis\" without leading into other terms that are incorrect or not relevant to the specific question. Despite its lack of clarity, the response is at least marginally related to the question due to the mention of \"electasis.\"\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"Fungal infection in,\" is incomplete and does not clearly convey the cause of hyperintensity in the image. Although it correctly identifies \"Fungal infection\" as the cause, the answer abruptly ends with \"in,\" making it unclear and incomplete. The lack of clarity and completion reduces its helpfulness and relevance to the question. While the key information is partially present, the response fails to deliver it in a clear and concise manner.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer contains a typographical error, \"Sround\" instead of \"Ground,\" but it still clearly points to the correct imaging finding, which is \"ground-glass opacity.\" Although there\\'s an error, the answer effectively conveys the key information needed: the presence of the ground-glass opacities, aligning well with the correct answer provided. However, the incomplete phrase \"and\" at the end of the response implies there might be additional information missing or an unfinished thought.\\n\\nOverall, the answer is relevant and includes the key finding despite some minor clarity issues due to the typo and the unfinished nature of the response. It provides the main relevant information that aligns with the correct answer.\\n\\nRating: 7/10',\n",
              "  'The model\\'s answer is both relevant and clear, providing the correct type of medical imaging, which is \"CT scan.\" The response is concise and directly addresses the question without unnecessary information. Since it correctly identifies the key piece of information, it meets the requirements for a full score.\\n\\nRating: 10/10',\n",
              "  'The model\\'s answer, \"Tumor atic nerve and,\" unfortunately does not provide the correct answer, \"Sciatic nerve.\" The response lacks accuracy, key information, and coherence, with the phrase \"Tumor atic nerve and\" being nonsensical and lacking both medical relevance and clarity. There is no indication of a correct or even close reference to the sciatic nerve, which is the specific nerve in question. Therefore, the response does not meet the criteria for helpfulness or relevance, and does not earn points for key information.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"Damcells infiltration of,\" does not provide any clear or relevant information to the question. It appears to be incomplete or possibly a typographical error. There is a lack of clarity, as the term \"Damcells\" does not have a known meaning in this context, which suggests it might be a misspelling or misunderstanding of \"inflammatory cell infiltration.\" Furthermore, the answer is not helpful as it doesn\\'t accurately address the query regarding what green arrows represent.\\n\\nNo key information is conveyed, and the response diverges significantly from the correct answer. There is no connection between \"Damcells\" and inflammatory cell infiltration, making it neither relevant nor useful. For these reasons, the response would not be considered close to the correct answer.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"Lateral radiograph,\" directly corresponds with the correct answer provided to the question. The response is clear, specific, and relevant, as it correctly identifies the type of radiograph depicted. While the answer is concise without additional context or explanation, it fulfills the primary requirement of accurately identifying the radiograph type. The addition of extra symbols or characters might not be necessary, but it does not detract from the correctness of the answer. Overall, the model\\'s straightforward and accurate response deserves a high score.\\n\\nRating: 10/10',\n",
              "  'The model\\'s answer, \"PET deoxyglucose PET /\", does mention PET, which is a key imaging modality similar to the correct answer, \"Fluorocholine PET\". However, it incorrectly specifies \"deoxyglucose PET\" (typically FDG PET) rather than \"Fluorocholine PET\", and includes an unnecessary slash at the end. The answer is not entirely accurate, but it partially relates to the correct category of imaging modality, PET. \\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"T1-weighted sagittal,\" provides the key information necessary to correctly identify the imaging technique. It includes \"T1-weighted,\" which aligns with the correct answer. The additional specification of \"sagittal\" conveys more detail about the orientation of the scan, which might be relevant depending on the context, although it was not required by the original question. The response is helpful, relevant, and clear, capturing the necessary aspect of the question while offering a little more detail. \\n\\nRating: 8/10',\n",
              "  'The model\\'s answer provides some relevant information indicating the presence of pneumonia, which is associated with lung infections and can be caused by COVID-19. However, it refers specifically to \"Pneumonia round, by LR@-@ 19 infection,\" which introduces ambiguity due to the non-standard terminology and symbols. The correct answer is GGO (ground-glass opacity), a specific finding often observed in COVID-19 pneumonia. The model\\'s response is not clear regarding the specific feature (GGO) and its association with COVID-19, although it partially aligns by mentioning pneumonia due to an infection. Despite the confusion, the model captures the primary concept that the CT image shows pneumonia due to an infection.\\n\\nRating: 5/10',\n",
              "  'The model\\'s answer, \"PET Emission Tomography (PET),\" contains a minor error in the repetition of \"PET\" as an abbreviation and in the terminology. However, it does convey the correct imaging technique by identifying \"PET,\" which stands for Positron Emission Tomography. The key information, identifying PET as the imaging technique, is present, despite the slight error in phrasing. The answer is quite close to the correct answer and provides relevant information, achieving its main goal. \\n\\n**Rating: 8/10**',\n",
              "  'The models answer identifies the condition as an osteytic lesion, but this term is not widely recognized in medical terminology and likely intended to be \"osteolytic lesion. Despite this, it captures the essence of a lytic or destructive process affecting the bone, which is a key characteristic of a lytic lesion. The attempt to specify the location as affecting the left femur head shows awareness of the relevant skeletal region, though it misses the precise detail of being in the femur rather than specifically its head. The response demonstrates partial relevance and a basic understanding necessary for identifying a possible bone lesion, albeit with a terminology error. \\n\\nRating: 5/10',\n",
              "  'The model\\'s answer is concise and directly addresses the question by confirming the use of an \"MRI scan\" to create the image. It matches the correct answer provided, demonstrating relevance and clarity. While brief, the response successfully conveys the necessary information without confusion or ambiguity. Since the answer is accurate and aligns with the expected response, it satisfies both helpfulness and relevance criteria effectively.\\n\\nRating: 10/10',\n",
              "  'The model\\'s answer, \"the cells,\" is not specific enough to be considered correct or relevant to the original question about which part of the mouse\\'s body was analyzed. The correct answer, \"Heart,\" identifies a specific organ, whereas \"the cells\" can refer to any part of the body and does not convey the necessary information about the particular body part analyzed. The response lacks relevance and clarity because it does not provide the crucial information required to answer the question accurately.\\n\\nRating: 2/10',\n",
              "  'The model\\'s answer, \"Fluorescence spectral imaging,\" is relevant and closely related to the correct answer, \"Multispectral images.\" Both types of imaging techniques are advanced methods used in microscopy to capture a range of spectral data. While the model\\'s answer does not exactly match the correct answer, it still provides a pertinent type of spectral imaging. The answer is clear and concise, even though it isn\\'t exactly the correct term. Given that it captures a related concept within the context of spectral imaging, the response is helpful.\\n\\nRating: 7/10',\n",
              "  'The model\\'s answer, \"A leaf-up view of a leaf surface,\" is somewhat unclear due to the phrase \"leaf-up,\" which might be a typographical error or an unintentional play on words. However, it captures the essential idea that the panel shows a view of the leaf surface. \\n\\nFor helpfulness, the model\\'s response does attempt to convey what is depicted, though the error may confuse readers.\\n\\nIn terms of relevance, the response is pertinent to the question and maintains focus on the subject, aligning with the asked context.\\n\\nFor clarity, while the main point is delivered, the unusual wording reduces the clarity of the message slightly.\\n\\nOverall, despite the awkward phrasing, the response contains the critical information needed to answer the question. Thus, a fair score should reflect the core point being successfully communicated despite minor linguistic errors.\\n\\nRating: 7/10',\n",
              "  'The model\\'s answer lacks clarity and coherence, making it difficult to determine its helpfulness and relevance. The response is filled with seemingly random words and phrases, such as \"signal signal histogram\" and \"L5 weights,\" which do not appear to be related to the question posed or the correct answer. Moreover, there are no clear references to \"difference,\" \"L2-norm,\" \"spectrum,\" or \"dStripe\"the key components of the correct answermaking it evident that the answer misses all the important information needed to accurately address the question.\\n\\nThe lack of any recognizable or meaningful content related to the original query means that the models response is not useful for someone trying to understand what the bottom panel shows in this context. Therefore, despite potential attempts at forming a response, the answer falls short of providing any key information.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"T2 us color myometrial-(\", does not provide a clear or coherent response to the question. The question asks about what a long thin arrow demonstrates, specifically referencing \"Fundus-isthmus length.\" The model\\'s answer contains terms like \"T2,\" \"us,\" and \"myometrial,\" which are relevant to medical imaging and anatomy, suggesting some understanding of medical context. However, the answer lacks clarity and doesn\\'t directly address or explain the concept of \"Fundus-isthmus length.\" The inclusion of additional symbols (\"-(\") further detracts from the clarity and usefulness of the response. It contains relevant terms, but ultimately fails to address the question properly.\\n\\nRating: 3/10',\n",
              "  'The model\\'s answer, \"3D image reconstruction,\" is closely aligned with the correct answer, \"3D image.\" It shows an understanding of the type of image being referred to and includes a key detail about the nature of the image being a reconstruction. While the word \"reconstruction\" is additional, it is still related to the original term and does not detract from the clarity or relevance of the answer. The answer is both helpful and relevant, providing a clear description that fits well within the context of the question. Given the proximity to the correct answer, the model\\'s response deserves a good score.\\n\\nRating: 9/10',\n",
              "  'The model\\'s answer is very close to the correct answer, \"endoscopic ultrasound  guided fine  needle aspiration.\" It includes both key components: the use of an endoscopic ultrasound and the fine-needle aspiration procedure. While there is a minor repetition with \"needle,\" it captures the essential information needed to understand the procedure performed for the enlarged hilar lymph node. The answer is helpful, relevant, and clear despite the slight issue with wording. \\n\\nRating: 9/10',\n",
              "  'The model\\'s answer, \"The region in,\" is incomplete and does not provide the necessary explanation or relevant information about what the yellow region denotes, which should be \"Reference segmentation.\" There is no key information provided, and the response lacks clarity and relevance to address the question. While it may be a typographical error or an unfinished sentence, the response does not fulfill the requirement for helpfulness and is missing the core answer. \\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"Left artery and left,\" lacks clarity and specificity. It does not directly address the question nor does it mention the splenic artery, which is the correct location for the thromboembolism. The response is vague and potentially misleading, as it does not provide any accurate or relevant information related to the medical query. Since the answer fails to include the primary key informationidentification of the thromboembolism in the splenic arteryit does not meet the criteria for a helpful or relevant response. \\n\\nRating: 2/10',\n",
              "  'The model\\'s answer, \"Left ventricle and,\" is not fully correct. While it mentions the left ventricle, which can be related to heart enlargement issues, the specific medical question asks about severe enlargement of the left atrium. Therefore, the model\\'s answer does not directly address the asked query of which part shows severe enlargement. The response is incomplete and lacks proper analysis related to the heart part mentioned in the questionnamely, the left atrium. While the mention of the \"left ventricle\" might be relevant in specific contexts of heart enlargement, it doesn\\'t directly address the question regarding the left atrium.\\n\\nHelpfulness: The answer is not helpful as it doesn\\'t accurately answer the question.\\nRelevance: The mention of the \"left ventricle\" is somewhat relevant in a general discussion about heart enlargement, but it is not relevant to the specific query.\\nClarity: The response ends abruptly with \"and,\" which reduces its clarity.\\n\\nRating: 3/10',\n",
              "  'The model\\'s answer, \"Slogand,\" appears to be a misspelling or completely unrelated term rather than a relevant term, specialty, or condition associated with the image related to neurology. It lacks clarity, relevance, and helpfulness, as it does not provide any indication of being associated with the correct field or information needed for the question. Since it does not offer any key information related to the correct answer, it cannot be considered close to accurate.\\n\\nRating: 0/10',\n",
              "  'The model\\'s answer partially aligns with the correct response by identifying the involvement of the \"8th cranial\" nerve, which is accurate. However, it incorrectly mentions \"Left\" instead of the \"7th cranial\" nerve, which detracts from the answer\\'s accuracy and clarity. The model\\'s answer does include one key piece of information, thus deserving partial credit. The response is somewhat helpful and relevant, though it lacks full precision. \\n\\nRating: 6/10',\n",
              "  'The model\\'s answer, \"A rendering rendering a ithan deposition a astrocyte. ron.\" is largely unclear and lacks coherence. It does not provide any relevant information in relation to the correct answer, which is a \"3D volume of perlecan within an NP chondron.\" Additionally, the mention of \"ithan deposition\" and \"astrocyte\" is not relevant to the context provided by the question. The repetition of \"rendering\" and the term \"ron\" at the end further contribute to its lack of clarity.\\n\\nWhile there may be some terms that seem related to biological topics, they do not convey the necessary key information about the image, nor do they connect well with the context of the NP chondron or perlecan. The response fails to offer pertinent or helpful information about the depiction in the white boundary box.\\n\\nGiven these issues, the response falls significantly short of providing a useful or relevant answer.\\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"The fibers on the aws and,\" appears incomplete and doesn\\'t provide enough details or relevant information to satisfactorily address the question about the filled flat arrowheads indicating muscle attachments above claws. There is no mention of muscle attachments, claws, or any connection to the correct answer. Without any key information provided, it fails to clearly or helpfully answer the question.\\n\\nRating: 1/10',\n",
              "  'The model\\'s response, \"Bilateral tered shad@-@ opacities in,\" is incomplete and lacks clarity. The key information in the correct answer is \"scattered ground glass opacities,\" and the model\\'s answer does not convey this critical information. Furthermore, the presence of special characters and incomplete words makes the response difficult to understand and reduces its helpfulness and relevance to the question. In summary, the model\\'s response fails to include the essential detail of \"ground glass opacities,\" which is the key information needed here.\\n\\nRating: 3/10',\n",
              "  'The model\\'s answer, \"Magnetic Resonance Imaging (MRI),\" is both clear and concise, directly addressing the question by naming the correct imaging modality. The response is relevant and helpful because it matches the expected correct answer provided. It presents the key information without unnecessary details or errors, demonstrating an understanding of the question. The presence of a period at the end doesn\\'t detract from the clarity or accuracy of the answer. \\n\\nOverall, the model has effectively addressed all aspects of the query with the essential information needed. \\n\\nRating: 10/10',\n",
              "  'The model\\'s answer, \"Right colon wall,\" is very close to the correct answer, \"Right colon.\" It effectively identifies the right area of the colon but adds the term \"wall,\" which is not necessary for the answer. However, this additional specification does not detract from the primary information and doesn\\'t indicate a misunderstanding. The response is clear and remains relevant to the question, clearly identifying the correct location of pneumatosis intestinalis as the right colon.\\n\\nRating: 9/10',\n",
              "  'The model\\'s answer is largely inaccurate and confusing. It includes several nonsensical and disconnected terms such as \"Anterior and and nerve\" and \"Anterior agenes,\" which are not recognized components of the optic tract. Additionally, the model erroneously repeats parts of the correct answer without offering clarity or accuracy.\\n\\nThe answer lacks clarity, coherence, and accuracy, failing to identify the correct components of the optic tract. As it doesn\\'t accurately present even one part correctly, it does not meet the threshold for at least half the score. \\n\\nRating: 1/10',\n",
              "  'The model\\'s answer, \"MRI Resonance Imaging (MRI),\" is somewhat redundant, as \"MRI\" already stands for \"Magnetic Resonance Imaging.\" Despite this, the model\\'s response correctly identifies the imaging type as MRI, which matches the correct answer. The answer is clear and relevant, and it includes the key information needed. While the repetition of \"Resonance Imaging\" is unnecessary, the essential information is conveyed accurately.\\n\\nRating: 8/10',\n",
              "  'The model\\'s answer \"Hand or position\" is not relevant or clear in relation to the question about the position of the forearm. The correct answer is \"Flexed,\" which pertains to the specific positioning of the forearm itself. The model\\'s response does not provide any helpful or related information about the position of the forearm and appears to misunderstand or misinterpret the question entirely. Since the answer doesn\\'t contain any relevant information toward the question, it doesn\\'t meet the criteria for even a partial score.\\n\\nRating: 0/10',\n",
              "  'The model\\'s answer, \"Two masses,\" is concise and relevant to the question. It correctly identifies the presence of two entities in the CT scan, which aligns with the number given in the correct answer. The term \"masses\" is appropriately used in a medical context to describe abnormal growths, including metastases. While the model does not explicitly use the word \"metastases,\" it is sufficiently clear to a medical professional that \"masses\" in this context likely refers to metastatic lesions. Therefore, the model\\'s response is both helpful and relevant, capturing the key information required.\\n\\nRating: 8/10',\n",
              "  'The model\\'s answer, \"Hyperar lesion lesion,\" does not provide relevant or clear information in response to the question. The term \"stellate scar\" is specific and crucial to understanding what is typically seen in the center of certain lesions, such as renal oncocytomas or fibromas. The provided answer repeats the word \"lesion\" and introduces \"Hyperar,\" which does not appear to correspond to any known medical terminology related to the context. This response lacks both helpfulness and relevance and does not convey the key information required to answer the question correctly.\\n\\nRating: 1/10'],\n",
              " [0.0,\n",
              "  0.1,\n",
              "  0.6,\n",
              "  0.1,\n",
              "  0.8,\n",
              "  0.3,\n",
              "  0.3,\n",
              "  0.1,\n",
              "  0.9,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  0.5,\n",
              "  0.5,\n",
              "  0.5,\n",
              "  0.2,\n",
              "  0.1,\n",
              "  0.3,\n",
              "  0.2,\n",
              "  0.8,\n",
              "  0.5,\n",
              "  0.3,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.8,\n",
              "  0.0,\n",
              "  0.8,\n",
              "  0.2,\n",
              "  0.1,\n",
              "  0.5,\n",
              "  0.8,\n",
              "  0.2,\n",
              "  0.2,\n",
              "  1.0,\n",
              "  0.5,\n",
              "  0.8,\n",
              "  0.0,\n",
              "  0.2,\n",
              "  0.1,\n",
              "  0.4,\n",
              "  0.5,\n",
              "  0.0,\n",
              "  0.6,\n",
              "  0.5,\n",
              "  0.1,\n",
              "  0.5,\n",
              "  0.3,\n",
              "  0.2,\n",
              "  0.4,\n",
              "  0.9,\n",
              "  0.1,\n",
              "  0.1,\n",
              "  0.1,\n",
              "  0.2,\n",
              "  0.1,\n",
              "  0.5,\n",
              "  0.1,\n",
              "  0.7,\n",
              "  0.3,\n",
              "  0.7,\n",
              "  0.7,\n",
              "  0.9,\n",
              "  0.1,\n",
              "  0.8,\n",
              "  0.1,\n",
              "  0.5,\n",
              "  0.5,\n",
              "  0.7,\n",
              "  1.0,\n",
              "  0.1,\n",
              "  0.1,\n",
              "  1.0,\n",
              "  0.5,\n",
              "  0.8,\n",
              "  0.5,\n",
              "  0.8,\n",
              "  0.5,\n",
              "  1.0,\n",
              "  0.2,\n",
              "  0.7,\n",
              "  0.7,\n",
              "  0.1,\n",
              "  0.3,\n",
              "  0.9,\n",
              "  0.9,\n",
              "  0.1,\n",
              "  0.2,\n",
              "  0.3,\n",
              "  0.0,\n",
              "  0.6,\n",
              "  0.1,\n",
              "  0.1,\n",
              "  0.3,\n",
              "  1.0,\n",
              "  0.9,\n",
              "  0.1,\n",
              "  0.8,\n",
              "  0.0,\n",
              "  0.8,\n",
              "  0.1],\n",
              " 0.41900000000000015)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_ablation_study(\n",
        "    train_df=train_df_new,\n",
        "    test_df=test_df,\n",
        "    ablation_configs=ablation_configs,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    subset_size=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFj2-hbKdqOy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
